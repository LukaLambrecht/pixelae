{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aad3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "# external modules\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "# framework modules\n",
    "sys.path.append('../')\n",
    "import plotting.plottools\n",
    "importlib.reload(plotting.plottools)\n",
    "from plotting.plottools import plot_histogram\n",
    "import training.prepare_training_set\n",
    "importlib.reload(training.prepare_training_set)\n",
    "from training.prepare_training_set import prepare_training_data_from_files\n",
    "# local modules\n",
    "import fake_anomaly\n",
    "importlib.reload(fake_anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a0aa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training set\n",
    "\n",
    "files = ([\n",
    "    '../data/data/ZeroBias-Run2023C-PromptReco-v1-DQMIO-PixelPhase1-Tracks-PXForward-clusterposition_xy_ontrack_PXDisk_+1_preprocessed.parquet',\n",
    "    #'../data/data/ZeroBias-Run2023C-PromptReco-v2-DQMIO-PixelPhase1-Tracks-PXForward-clusterposition_xy_ontrack_PXDisk_+1_preprocessed.parquet',\n",
    "    #'../data/data/ZeroBias-Run2023C-PromptReco-v3-DQMIO-PixelPhase1-Tracks-PXForward-clusterposition_xy_ontrack_PXDisk_+1_preprocessed.parquet',\n",
    "    #'../data/data/ZeroBias-Run2023C-PromptReco-v4-DQMIO-PixelPhase1-Tracks-PXForward-clusterposition_xy_ontrack_PXDisk_+1_preprocessed.parquet',\n",
    "    #'../data/data/ZeroBias-Run2023D-PromptReco-v1-DQMIO-PixelPhase1-Tracks-PXForward-clusterposition_xy_ontrack_PXDisk_+1_preprocessed.parquet',\n",
    "    #'../data/data/ZeroBias-Run2023D-PromptReco-v2-DQMIO-PixelPhase1-Tracks-PXForward-clusterposition_xy_ontrack_PXDisk_+1_preprocessed.parquet',\n",
    "])\n",
    "kwargs = ({\n",
    "    'verbose': True,\n",
    "    'entries_threshold': 10000,\n",
    "    'skip_first_lumisections': 5\n",
    "})\n",
    "(eval_data, eval_runs, eval_lumis) = prepare_training_data_from_files(files, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1d94bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a mask where values are often zero\n",
    "\n",
    "shape_mask = (np.sum(eval_data[:,:,:,0]==0, axis=0)>len(eval_data)/2.)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "plot_histogram(shape_mask, fig=fig, ax=ax, caxrange=(-0.01,1))\n",
    "ax.text(0.02, 1.02, 'Shape mask', transform=ax.transAxes, fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3abf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load keras model\n",
    "\n",
    "modelname = '../models/model_20231115_Run2023C-v1_PixelPhase1-Tracks-PXForward-clusterposition_xy_ontrack_PXDisk_+1.keras'\n",
    "model = keras.models.load_model(modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ea9ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load average occupancy or error of training set\n",
    "\n",
    "avgresponsename = '../models/model_20231115_Run2023C-v1_PixelPhase1-Tracks-PXForward-clusterposition_xy_ontrack_PXDisk_+1_avgoccupancy.npy'\n",
    "avgresponse = np.load(avgresponsename)\n",
    "avgresponse = np.square(avgresponse)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "plot_histogram(avgresponse, fig=fig, ax=ax)\n",
    "ax.text(0.02, 1.02, 'Average response on training set', transform=ax.transAxes, fontsize=12)\n",
    "avgresponse[avgresponse==0] = 1\n",
    "avgresponse = np.expand_dims(avgresponse, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c800fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a collection of fake anomalies\n",
    "\n",
    "nanomalies = 100\n",
    "random_indices = np.random.choice(len(eval_data), size=nanomalies, replace=False)\n",
    "\n",
    "anomalies = np.zeros((nanomalies, eval_data.shape[1], eval_data.shape[2], 1))\n",
    "params = []\n",
    "for newidx,origidx in enumerate(random_indices):\n",
    "    hist = eval_data[origidx,:,:,0]\n",
    "    (anomalous_hist, paramdict) = fake_anomaly.dead_rectangle(hist, shape_mask=~shape_mask)\n",
    "    #(anomalous_hist, paramdict) = fake_anomaly.dead_sector(hist)\n",
    "    #(anomalous_hist, paramdict) = fake_anomaly.hot_rectangle(hist, shape_mask=~shape_mask)\n",
    "    #(anomalous_hist, paramdict) = fake_anomaly.hot_sector(hist)\n",
    "    anomalies[newidx,:,:,0] = anomalous_hist\n",
    "    params.append(paramdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4c1cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "\n",
    "predictions = model.predict(eval_data)\n",
    "predictions[predictions<0] = 0.\n",
    "predictions[:,shape_mask] = 0.\n",
    "\n",
    "predictions_anomalies = model.predict(anomalies)\n",
    "predictions_anomalies[predictions_anomalies<0] = 0.\n",
    "predictions_anomalies[:,shape_mask] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0785040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate squared difference\n",
    "errors = np.square(eval_data - predictions)\n",
    "errors_anomalies = np.square(anomalies - predictions_anomalies)\n",
    "\n",
    "# space correction\n",
    "errors_corrected = errors/avgresponse\n",
    "errors_anomalies_corrected = errors_anomalies/avgresponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b105025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots\n",
    "\n",
    "nplots = 5\n",
    "plotids = np.random.choice(len(anomalies), size=nplots, replace=False)\n",
    "\n",
    "for i in plotids:\n",
    "    fig,axs = plt.subplots(figsize=(30,6), ncols=4)\n",
    "    plot_histogram(anomalies[i,:,:,0], fig=fig, ax=axs[0])\n",
    "    plot_histogram(predictions_anomalies[i,:,:,0], fig=fig, ax=axs[1])\n",
    "    plot_histogram(errors_anomalies[i,:,:,0], fig=fig, ax=axs[2], caxrange=(-0.001, 0.01))\n",
    "    plot_histogram(errors_anomalies_corrected[i,:,:,0], fig=fig, ax=axs[3], caxrange=(-0.01, 0.5))\n",
    "    axs[0].text(0.02, 1.02, 'Fake anomaly', transform=axs[0].transAxes, fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4dfc7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
