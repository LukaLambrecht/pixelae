{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aad3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "# external modules\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "# framework modules\n",
    "sys.path.append('../')\n",
    "import plotting.plottools\n",
    "importlib.reload(plotting.plottools)\n",
    "from plotting.plottools import plot_histogram\n",
    "import training.prepare_training_set\n",
    "importlib.reload(training.prepare_training_set)\n",
    "from training.prepare_training_set import prepare_training_data_from_files\n",
    "import training.patternfiltering\n",
    "importlib.reload(training.patternfiltering)\n",
    "from training.patternfiltering import contains_any_pattern\n",
    "import datagen.fake_anomaly\n",
    "importlib.reload(datagen.fake_anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a0aa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the evaluation sets\n",
    "\n",
    "mes = ([\n",
    "    'PixelPhase1-Tracks-PXForward-clusterposition_xy_ontrack_PXDisk_+1',\n",
    "    'PixelPhase1-Tracks-PXForward-clusterposition_xy_ontrack_PXDisk_+2',\n",
    "    'PixelPhase1-Tracks-PXForward-clusterposition_xy_ontrack_PXDisk_+3',\n",
    "    'PixelPhase1-Tracks-PXForward-clusterposition_xy_ontrack_PXDisk_-1',\n",
    "    'PixelPhase1-Tracks-PXForward-clusterposition_xy_ontrack_PXDisk_-2',\n",
    "    'PixelPhase1-Tracks-PXForward-clusterposition_xy_ontrack_PXDisk_-3',\n",
    "])\n",
    "\n",
    "eras = ([\n",
    "    'Run2023C-PromptReco-v1'\n",
    "])\n",
    "\n",
    "kwargs = ({\n",
    "    'verbose': True,\n",
    "    'entries_threshold': 10000,\n",
    "    'skip_first_lumisections': 5,\n",
    "    'veto_patterns': [np.zeros((2,2)), np.zeros((2,1)), np.zeros((1,2))]\n",
    "})\n",
    "\n",
    "eval_data = {}\n",
    "for me in mes:\n",
    "    files = ['../data/data/ZeroBias-{}-DQMIO-{}_preprocessed.parquet'.format(era, me) for era in eras]\n",
    "    (data, runs, lumis) = prepare_training_data_from_files(files, **kwargs)\n",
    "    eval_data[me] = {'data': data, 'runs': runs, 'lumis': lumis}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1d94bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make masks where values are often zero\n",
    "\n",
    "for me in mes:\n",
    "    this_eval_data = eval_data[me]['data']\n",
    "    shape_mask = (np.sum(this_eval_data[:,:,:,0]==0, axis=0)>len(this_eval_data)*0.5)\n",
    "    \n",
    "    # temp: also set edges to zero\n",
    "    #shape_mask[0,:] = 1\n",
    "    #shape_mask[-1,:] = 1\n",
    "    #shape_mask[:,0] = 1\n",
    "    #shape_mask[:,-1] = 1\n",
    "    \n",
    "    eval_data[me]['shape_mask'] = shape_mask\n",
    "\n",
    "fig,axs = plt.subplots(figsize=(len(mes*6),6), ncols=len(mes))\n",
    "for i, me in enumerate(mes):\n",
    "    plot_histogram(eval_data[me]['shape_mask'], fig=fig, ax=axs[i], caxrange=(-0.01,1))\n",
    "    axs[i].text(0.02, 1.02, 'Shape mask for {}'.format(me.split('_ontrack_')[1]), transform=axs[i].transAxes, fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3abf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load keras models\n",
    "\n",
    "modelbase = '../models/output_20231115/model_20231115_Run2023C-v1'\n",
    "\n",
    "for me in mes:\n",
    "    modelname = '{}_{}.keras'.format(modelbase, me)\n",
    "    model = keras.models.load_model(modelname)\n",
    "    eval_data[me]['model'] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ea9ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load average occupancy or error of training sets\n",
    "\n",
    "for me in mes:\n",
    "    avgresponsename = '{}_{}_avgoccupancy.npy'.format(modelbase, me)\n",
    "    avgresponse = np.load(avgresponsename)\n",
    "    avgresponse = np.square(avgresponse)\n",
    "    eval_data[me]['avgresponse'] = avgresponse\n",
    "\n",
    "fig,axs = plt.subplots(figsize=(len(mes*6),6), ncols=len(mes))\n",
    "for i, me in enumerate(mes):\n",
    "    plot_histogram(eval_data[me]['avgresponse'], fig=fig, ax=axs[i])\n",
    "    axs[i].text(0.02, 1.02, 'Average response for {}'.format(me.split('_ontrack_')[1]), transform=axs[i].transAxes, fontsize=15)\n",
    "    \n",
    "for me in mes:\n",
    "    avgresponse = eval_data[me]['avgresponse']\n",
    "    avgresponse[avgresponse==0] = 1\n",
    "    avgresponse = np.expand_dims(avgresponse, axis=2)\n",
    "    eval_data[me]['avgresponse'] = avgresponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c800fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make collections of fake anomalies\n",
    "\n",
    "nanomalies = 6000\n",
    "\n",
    "for me in mes:\n",
    "    this_eval_data = eval_data[me]['data']\n",
    "    this_shape_mask = eval_data[me]['shape_mask']\n",
    "    random_indices = np.random.choice(len(this_eval_data), size=nanomalies, replace=True)\n",
    "    anomalies = np.zeros((nanomalies, this_eval_data.shape[1], this_eval_data.shape[2], 1))\n",
    "    for newidx,origidx in enumerate(random_indices):\n",
    "        hist = this_eval_data[origidx,:,:,0]\n",
    "        (anomalous_hist, paramdict) = datagen.fake_anomaly.dead_rectangle(hist, rectangle_min_pixels=2, shape_mask=~this_shape_mask)\n",
    "        anomalies[newidx,:,:,0] = anomalous_hist\n",
    "    eval_data[me]['anomalies'] = anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4c1cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the models\n",
    "\n",
    "for me in mes:\n",
    "    this_eval_data = eval_data[me]['data']\n",
    "    this_anomalies = eval_data[me]['anomalies']\n",
    "    this_model = eval_data[me]['model']\n",
    "    this_shape_mask = eval_data[me]['shape_mask']\n",
    "    this_avgresponse = eval_data[me]['avgresponse']\n",
    "    \n",
    "    predictions = this_model.predict(this_eval_data)\n",
    "    predictions[predictions<0] = 0.\n",
    "    predictions[:,this_shape_mask] = 0.\n",
    "\n",
    "    predictions_anomalies = this_model.predict(this_anomalies)\n",
    "    predictions_anomalies[predictions_anomalies<0] = 0.\n",
    "    predictions_anomalies[:,this_shape_mask] = 0.\n",
    "    \n",
    "    errors = np.square(this_eval_data - predictions)\n",
    "    errors[:,this_shape_mask] = 0.\n",
    "    errors_anomalies = np.square(this_anomalies - predictions_anomalies)\n",
    "    errors_anomalies[:,this_shape_mask] = 0.\n",
    "\n",
    "    errors_corrected = errors/this_avgresponse\n",
    "    errors_anomalies_corrected = errors_anomalies/this_avgresponse\n",
    "    \n",
    "    eval_data[me]['errors_corrected'] = errors_corrected\n",
    "    eval_data[me]['errors_anomalies_corrected'] = errors_anomalies_corrected\n",
    "    # maybe later add predictions and uncorrected errors as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4dfc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scan thresholds to make ROC curves\n",
    "\n",
    "thresholds = [0.25, 0.4, 0.5, 0.6, 0.75, 1]\n",
    "patterns = [-np.ones((2,2)), -np.ones((2,1)), -np.ones((1,2))]\n",
    "\n",
    "for me in mes:\n",
    "    print('Running on ME {}'.format(me))\n",
    "    errors_corrected = eval_data[me]['errors_corrected']\n",
    "    errors_anomalies_corrected = eval_data[me]['errors_anomalies_corrected']\n",
    "    s_eff = []\n",
    "    b_eff = []\n",
    "    for i, threshold in enumerate(thresholds):\n",
    "        print('  Threshold {} of {}'.format(i+1, len(thresholds)))\n",
    "        errors_scaled = np.where(errors_corrected>threshold, -1, errors_corrected)\n",
    "        errors_anomalies_scaled = np.where(errors_anomalies_corrected>threshold, -1, errors_anomalies_corrected)\n",
    "        flags = contains_any_pattern(errors_scaled[:,:,:,0], patterns)\n",
    "        flags_anomalies = contains_any_pattern(errors_anomalies_scaled[:,:,:,0], patterns)\n",
    "        #print('Threshold: {}'.format(threshold))\n",
    "        #print('{} out of {} non-anomalous histograms were tagged'.format(sum(flags), len(flags)))\n",
    "        #print('{} out of {} anomalous histograms were tagged'.format(sum(flags_anomalies), len(flags_anomalies)))\n",
    "        s_eff.append( sum(flags_anomalies)/len(flags_anomalies) )\n",
    "        b_eff.append( sum(flags)/len(flags) )\n",
    "    eval_data[me]['roc'] = (s_eff, b_eff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be1af16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a plot\n",
    "\n",
    "colors = ({\n",
    "    'PixelPhase1-Tracks-PXForward-clusterposition_xy_ontrack_PXDisk_+1': 'dodgerblue',\n",
    "    'PixelPhase1-Tracks-PXForward-clusterposition_xy_ontrack_PXDisk_+2': 'darkviolet',\n",
    "    'PixelPhase1-Tracks-PXForward-clusterposition_xy_ontrack_PXDisk_+3': 'crimson',\n",
    "    'PixelPhase1-Tracks-PXForward-clusterposition_xy_ontrack_PXDisk_-1': 'lightskyblue',\n",
    "    'PixelPhase1-Tracks-PXForward-clusterposition_xy_ontrack_PXDisk_-2': 'orchid',\n",
    "    'PixelPhase1-Tracks-PXForward-clusterposition_xy_ontrack_PXDisk_-3': 'orangered',\n",
    "})\n",
    "fig,ax = plt.subplots()\n",
    "for me in mes:\n",
    "    s_eff, b_eff = eval_data[me]['roc']\n",
    "    ax.plot(b_eff, s_eff, label=me.split('_ontrack_')[1], color=colors[me], linewidth=2)\n",
    "ax.legend(fontsize=12)\n",
    "ax.set_xlabel('False alarm rate', fontsize=15)\n",
    "ax.set_ylabel('True anomaly efficiency', fontsize=15)\n",
    "ax.grid()\n",
    "ax.set_ylim((0,1))\n",
    "ax.set_xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2229e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
