{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f0d2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install converter package\n",
    "# see https://onnx.ai/sklearn-onnx/introduction.html\n",
    "\n",
    "#!pip install --user skl2onnx\n",
    "\n",
    "# after installation, need to restart the session and make sure to tick 'use python packages installed in CERNBox'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba9bb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import joblib\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "thisdir = os.getcwd()\n",
    "topdir = os.path.abspath(os.path.join(thisdir, '../../../../'))\n",
    "sys.path.append(topdir)\n",
    "\n",
    "import tools.iotools as iotools\n",
    "import tools.dftools as dftools\n",
    "import plotting.plottools as plottools\n",
    "from studies.clusters_2024.plotting.plot_cluster_occupancy import plot_cluster_occupancy\n",
    "from studies.clusters_2024.nmf.nmf_testing_pattern import make_preprocessors\n",
    "from studies.clusters_2024.nmf.nmf_testing_pattern import load_nmfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7402d64",
   "metadata": {},
   "source": [
    "### Load some previously stored models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad80cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set eras and layers for models to retrieve\n",
    "\n",
    "eras = [\n",
    "    'C-v1'\n",
    "]\n",
    "\n",
    "layers = [\n",
    "    'BPix1',\n",
    "    'BPix2',\n",
    "    'BPix3',\n",
    "    'BPix4'\n",
    "]\n",
    "\n",
    "# load nmf models\n",
    "\n",
    "modeldir = '../output_20250604/models'\n",
    "\n",
    "# set path\n",
    "nmf_files = {}\n",
    "for era in eras:\n",
    "    nmf_files[era] = {}\n",
    "    for layer in layers:\n",
    "        nmf_files[era][layer] = os.path.join(modeldir, f'nmf_model_{layer.upper()}_{era}.pkl')\n",
    "    \n",
    "# existence check\n",
    "missing = []\n",
    "for era in eras:\n",
    "    for layer, f in nmf_files[era].items():\n",
    "        if not os.path.exists(f): missing.append(f)\n",
    "if len(missing) > 0:\n",
    "    raise Exception(f'The following files do not exist: {missing}')\n",
    "    \n",
    "# load models\n",
    "nmfs = {}\n",
    "for era in eras:\n",
    "    nmfs[era] = {}\n",
    "    for layer in layers:\n",
    "        nmf_file = nmf_files[era][layer]\n",
    "        nmf = joblib.load(nmf_file)\n",
    "        nmfs[era][layer] = nmf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4797e032",
   "metadata": {},
   "source": [
    "### Store and re-load models in ONNX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca42e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store nmf models in ONNX format\n",
    "\n",
    "# set eras and layers for models to store\n",
    "\n",
    "eras = [\n",
    "    'C-v1'\n",
    "]\n",
    "\n",
    "layers = [\n",
    "    'BPix1',\n",
    "    #'BPix2',\n",
    "    #'BPix3',\n",
    "    #'BPix4'\n",
    "]\n",
    "\n",
    "import nmf2d_onnx\n",
    "importlib.reload(nmf2d_onnx)\n",
    "\n",
    "# wrap models\n",
    "from nmf2d_onnx import NMF2DTransformWrapper\n",
    "nmfs_wrapped = {}\n",
    "n_approx_steps = 1000\n",
    "for era in eras:\n",
    "    nmfs_wrapped[era] = {}\n",
    "    for layer in layers:\n",
    "        nmfs_wrapped[era][layer] = NMF2DTransformWrapper(nmfs[era][layer], n_approx_steps = n_approx_steps)\n",
    "\n",
    "# register the converter\n",
    "from skl2onnx import update_registered_converter\n",
    "from nmf2d_onnx import skl2onnx_shape_calculator\n",
    "from nmf2d_onnx import skl2onnx_converter\n",
    "update_registered_converter(\n",
    "    NMF2DTransformWrapper, \"NMF2DTransformWrapper\",\n",
    "    skl2onnx_shape_calculator,\n",
    "    skl2onnx_converter)\n",
    "\n",
    "# get expected input shape\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "initial_types = {}\n",
    "for layer in layers:\n",
    "    shape = nmfs[eras[0]][layer].xshape\n",
    "    initial_types[layer] = [\n",
    "        ('input', FloatTensorType([None, *shape])),\n",
    "    ]\n",
    "\n",
    "# convert models to ONNX\n",
    "from skl2onnx import convert_sklearn\n",
    "for era in eras:\n",
    "    for layer in layers:\n",
    "        nmf_onnx = convert_sklearn(nmfs_wrapped[era][layer], initial_types=initial_types[layer])\n",
    "        with open(f'test_{era}_{layer}.onnx', \"wb\") as f:\n",
    "            f.write(nmf_onnx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ad4959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read ONNX models\n",
    "\n",
    "import onnxruntime as rt\n",
    "\n",
    "nmfs_onnx = {}\n",
    "for era in eras:\n",
    "    nmfs_onnx[era] = {}\n",
    "    for layer in layers:\n",
    "        nmfs_onnx[era][layer] = rt.InferenceSession(f\"test_{era}_{layer}.onnx\", providers=[\"CPUExecutionProvider\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf84609",
   "metadata": {},
   "source": [
    "### Read some data and compare predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f1bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set era and layers for evaluation\n",
    "\n",
    "era = 'C-v1'\n",
    "layers = [\n",
    "    'BPix1',\n",
    "    #'BPix2',\n",
    "    #'BPix3',\n",
    "    #'BPix4'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715472c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to input files\n",
    "\n",
    "# settings\n",
    "datadir = '/eos/user/l/llambrec/dialstools-output'\n",
    "year = '2024'\n",
    "dataset = 'ZeroBias'\n",
    "reco = 'PromptReco'\n",
    "mebase = 'PixelPhase1-Phase1_MechanicalView-PXBarrel-'\n",
    "mebase += 'clusters_per_SignedModuleCoord_per_SignedLadderCoord_PXLayer_'\n",
    "all_layers = ['BPix1', 'BPix2', 'BPix3', 'BPix4']\n",
    "\n",
    "# find files corresponding to settings\n",
    "input_files = {}\n",
    "mainera, version = era.split('-', 1)\n",
    "input_files[era] = {}\n",
    "for layer in all_layers:\n",
    "    f = f'{dataset}-Run{year}{mainera}-{reco}-{version}-DQMIO-{mebase}{layer[-1]}.parquet'\n",
    "    f = os.path.join(datadir, f)\n",
    "    input_files[era][layer] = f\n",
    "    \n",
    "# existence check\n",
    "missing = []\n",
    "present = []\n",
    "for _, values in input_files.items():\n",
    "    for layer, f in values.items():\n",
    "        if not os.path.exists(f): missing.append(f)\n",
    "        else: present.append(f)\n",
    "if len(missing) > 0:\n",
    "    raise Exception(f'The following files do not exist: {missing}')\n",
    "else:\n",
    "    print(f'Found {len(present)} files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa94124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make preprocessors\n",
    "\n",
    "global_normalization = 'avg'\n",
    "local_normalization = 'avg_era_C-v1'\n",
    "preprocessors = make_preprocessors([era], all_layers,\n",
    "                                   global_normalization = global_normalization,\n",
    "                                   local_normalization = local_normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95bb691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load available run and lumisection numbers\n",
    "\n",
    "dftemp = iotools.read_parquet(input_files[era][layers[0]], columns=['run_number', 'ls_number', 'entries'])\n",
    "dftemp = dftemp[dftemp['entries']>0.5e6]\n",
    "available_run_numbers = dftemp['run_number'].values\n",
    "available_ls_numbers = dftemp['ls_number'].values\n",
    "unique_runs = np.unique(available_run_numbers)\n",
    "\n",
    "print('Available runs:')\n",
    "print(unique_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f522b876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some random (or not random) examples\n",
    "\n",
    "# random lumisections\n",
    "nplot = 1\n",
    "random_ids = np.random.choice(len(available_run_numbers), size=min(nplot, len(available_run_numbers)), replace=False)\n",
    "selected_run_numbers = available_run_numbers[random_ids]\n",
    "selected_ls_numbers = available_ls_numbers[random_ids]\n",
    "\n",
    "# alternative: specific selected lumisections\n",
    "#selected_runlumis = [(383486, 101), (383486, 102), (383486, 103)]\n",
    "#selected_run_numbers = [el[0] for el in selected_runlumis]\n",
    "#selected_ls_numbers = [el[1] for el in selected_runlumis]\n",
    "\n",
    "if len(selected_run_numbers) > 0:\n",
    "    \n",
    "    # load data\n",
    "    print('Loading data...')\n",
    "    dfs = {}\n",
    "    mes = {}\n",
    "    for layer in layers:\n",
    "        dfs[layer] = iotools.read_lumisections(input_files[era][layer], selected_run_numbers, selected_ls_numbers, mode='batched')\n",
    "        mes[layer], runs, lumis = dftools.get_mes(dfs[layer], xbinscolumn='x_bin', ybinscolumn='y_bin', runcolumn='run_number', lumicolumn='ls_number')\n",
    "    \n",
    "    # preprocess\n",
    "    print('Processing...')\n",
    "    mes_preprocessed = {}\n",
    "    mes_preprocessed_extra = {}\n",
    "    for layer in layers:\n",
    "        mes_preprocessed[layer] = preprocessors[era][layer].preprocess(dfs[layer])\n",
    "        this_mes_preprocessed = np.copy(mes_preprocessed[layer])\n",
    "        if preprocessors is not None:\n",
    "            threshold = 5\n",
    "            this_mes_preprocessed[this_mes_preprocessed > threshold] = threshold\n",
    "        if preprocessors is not None:\n",
    "            this_mes_preprocessed[this_mes_preprocessed == 0] = 1\n",
    "        mes_preprocessed_extra[layer] = this_mes_preprocessed\n",
    "    \n",
    "    # predict direct\n",
    "    print('Running raw inference...')\n",
    "    mes_pred = {}\n",
    "    for layer in layers:\n",
    "        mes_pred[layer] = nmfs[era][layer].predict(mes_preprocessed_extra[layer])\n",
    "        \n",
    "    # predict\n",
    "    print('Running ONNX inference...')\n",
    "    mes_pred_onnx = {}\n",
    "    for layer in layers:\n",
    "        input_name = nmfs_onnx[era][layer].get_inputs()[0].name\n",
    "        label_name = nmfs_onnx[era][layer].get_outputs()[0].name\n",
    "        mes_pred_onnx[layer] = nmfs_onnx[era][layer].run([label_name], {input_name: mes_preprocessed_extra[layer].astype(np.float32)})[0]\n",
    "        \n",
    "    # make the plots\n",
    "    print('Plotting...')\n",
    "    for idx in range(len(selected_run_numbers)):\n",
    "        run = runs[idx]\n",
    "        lumi = lumis[idx]\n",
    "        for layer in layers:\n",
    "            me_orig = mes[layer][idx, :, :]\n",
    "            me_preprocessed = mes_preprocessed[layer][idx, :, :]\n",
    "            me_pred = mes_pred[layer][idx, :, :]\n",
    "            me_pred_onnx = mes_pred_onnx[layer][idx, :, :]\n",
    "    \n",
    "            # initialize figure\n",
    "            nrows = 1\n",
    "            figheight = 6\n",
    "            fig, axs = plt.subplots(ncols=4, nrows=nrows, figsize=(24, figheight), squeeze=False)\n",
    "            \n",
    "            # plot raw data\n",
    "            fig, axs[0, 0] = plot_cluster_occupancy(me_orig, fig=fig, ax=axs[0, 0],\n",
    "                   title='Raw', titlesize=15,\n",
    "                   xaxtitlesize=15, yaxtitlesize=15,\n",
    "                   ticklabelsize=12, colorticklabelsize=12,\n",
    "                   docolorbar=True, caxtitle='Number of clusters',\n",
    "                   caxtitlesize=15, caxtitleoffset=15)\n",
    "        \n",
    "            # plot preprocessed, reconstructed and ONNX reconstructed\n",
    "            fig, axs[0, 1] = plot_cluster_occupancy(me_preprocessed, fig=fig, ax=axs[0, 1],\n",
    "                   title='Input', titlesize=15,\n",
    "                   xaxtitlesize=15, yaxtitlesize=15,\n",
    "                   ticklabelsize=12, colorticklabelsize=12,\n",
    "                   docolorbar=True, caxtitle='Number of clusters\\n(normalized)',\n",
    "                   caxrange=(1e-6,2),\n",
    "                   caxtitlesize=15, caxtitleoffset=30)\n",
    "            fig, axs[0, 2] = plot_cluster_occupancy(me_pred, fig=fig, ax=axs[0, 2],\n",
    "                   title='Reconstructed', titlesize=15,\n",
    "                   xaxtitlesize=15, yaxtitlesize=15,\n",
    "                   ticklabelsize=12, colorticklabelsize=12,\n",
    "                   docolorbar=True, caxtitle='Number of clusters\\n(normalized)',\n",
    "                   caxrange=(1e-6,2),\n",
    "                   caxtitlesize=15, caxtitleoffset=30)\n",
    "            fig, axs[0, 3] = plot_cluster_occupancy(me_pred_onnx, fig=fig, ax=axs[0, 3],\n",
    "                   title='ONNX reconstructed', titlesize=15,\n",
    "                   xaxtitlesize=15, yaxtitlesize=15,\n",
    "                   ticklabelsize=12, colorticklabelsize=12,\n",
    "                   docolorbar=True, caxtitle='Number of clusters\\n(normalized)',\n",
    "                   caxrange=(1e-6,2),\n",
    "                   caxtitlesize=15, caxtitleoffset=30)\n",
    "                \n",
    "            # plot aesthetics\n",
    "            plt.subplots_adjust(wspace=0.55)\n",
    "            if str(layer)=='BPix1': plt.subplots_adjust(hspace=-0.65)\n",
    "            if str(layer)=='BPix2': plt.subplots_adjust(hspace=-0.35)\n",
    "            title = f'Run {run}, LS {lumi}, layer {layer}'\n",
    "            axs[0, 0].text(0.01, 1.3, title, fontsize=15, transform=axs[0, 0].transAxes)\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "            # plot the difference between both reconstructions\n",
    "            me_pred_diff = np.abs(me_pred - me_pred_onnx)\n",
    "            fig, ax = plt.subplots()\n",
    "            fig, ax = plot_cluster_occupancy(me_pred_diff, fig=fig, ax=ax,\n",
    "                   title='Difference between raw and ONNX reconstruction', titlesize=15,\n",
    "                   xaxtitlesize=15, yaxtitlesize=15,\n",
    "                   ticklabelsize=12, colorticklabelsize=12,\n",
    "                   docolorbar=True, caxtitle='Difference',\n",
    "                   caxrange=(0, 0.01),\n",
    "                   caxtitlesize=15, caxtitleoffset=15)\n",
    "            title = f'Run {run}, LS {lumi}'\n",
    "            ax.text(0.01, 1.3, title, fontsize=15, transform=ax.transAxes)\n",
    "            plt.show()\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffcce52",
   "metadata": {},
   "source": [
    "### Read a larger batch of data and compare runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5bf29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set era and layers for evaluation\n",
    "\n",
    "era = 'C-v1'\n",
    "layers = [\n",
    "    'BPix1',\n",
    "    #'BPix2',\n",
    "    #'BPix3',\n",
    "    #'BPix4'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77daffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# read data\n",
    "for layer in layers:\n",
    "    batch_size = int(5000 / int(layer[-1]))\n",
    "    print(f'Running on layer {layer}')\n",
    "    \n",
    "    # load the data\n",
    "    print('  Loading data...')\n",
    "    df = iotools.read_parquet(input_files[era][layer], verbose=False, batch_size=batch_size, first_batch=0, last_batch=0)\n",
    "    df = df[df['entries']>0]\n",
    "    \n",
    "    # preprocess\n",
    "    print('Processing...')\n",
    "    mes_preprocessed = preprocessors[era][layer].preprocess(df)\n",
    "    if preprocessors is not None:\n",
    "        threshold = 5\n",
    "        mes_preprocessed[mes_preprocessed > threshold] = threshold\n",
    "    if preprocessors is not None:\n",
    "        mes_preprocessed[mes_preprocessed == 0] = 1\n",
    "\n",
    "    # predict direct\n",
    "    print('Running raw inference...')\n",
    "    starttime = time.time()\n",
    "    mes_pred = nmfs[era][layer].predict(mes_preprocessed)\n",
    "    stoptime = time.time()\n",
    "    timing_raw = stoptime - starttime\n",
    "    timing_raw_avg = timing_raw / len(df)\n",
    "        \n",
    "    # predict\n",
    "    print('Running ONNX inference...')\n",
    "    starttime = time.time()\n",
    "    input_name = nmfs_onnx[era][layer].get_inputs()[0].name\n",
    "    label_name = nmfs_onnx[era][layer].get_outputs()[0].name\n",
    "    mes_pred_onnx = nmfs_onnx[era][layer].run([label_name], {input_name: mes_preprocessed.astype(np.float32)})[0]\n",
    "    stoptime = time.time()\n",
    "    timing_onnx = stoptime - starttime\n",
    "    timing_onnx_avg = timing_onnx / len(df)\n",
    "    \n",
    "    # printouts\n",
    "    print(f'=== Timing for layer {layer} ===')\n",
    "    print(f'  - on {len(df)} instances:' + ' raw: {:.3f} s,  ONNX: {:.3f} s'.format(timing_raw, timing_onnx))\n",
    "    print(f'  - avg per instances:' + ' raw: {:.3f} ms,  ONNX: {:.3f} ms'.format(timing_raw_avg*1000, timing_onnx_avg*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ca9e5f",
   "metadata": {},
   "source": [
    "### Plot model saving, loading, and evaluation time as a function of number of approximation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c95323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "\n",
    "# settings\n",
    "era = 'C-v1'\n",
    "layers = [\n",
    "    'BPix1',\n",
    "    'BPix2',\n",
    "    'BPix3',\n",
    "    'BPix4'\n",
    "]\n",
    "batch_size = 5000\n",
    "points = [10, 20, 50, 100, 200, 500, 1000]\n",
    "nrepeats = 10\n",
    "\n",
    "import nmf2d_onnx\n",
    "importlib.reload(nmf2d_onnx)\n",
    "from nmf2d_onnx import NMF2DTransformWrapper\n",
    "from skl2onnx import update_registered_converter\n",
    "from nmf2d_onnx import skl2onnx_shape_calculator\n",
    "from nmf2d_onnx import skl2onnx_converter\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "import onnxruntime as rt\n",
    "\n",
    "# initializations\n",
    "store_times = {}\n",
    "store_sizes = {}\n",
    "model_sizes = {}\n",
    "load_times = {}\n",
    "run_times = {}\n",
    "accuracy = {}\n",
    "\n",
    "# register the converter\n",
    "update_registered_converter(\n",
    "        NMF2DTransformWrapper, \"NMF2DTransformWrapper\",\n",
    "        skl2onnx_shape_calculator,\n",
    "        skl2onnx_converter)\n",
    "\n",
    "# get expected input shape\n",
    "initial_types = {}\n",
    "for layer in layers:\n",
    "    shape = nmfs[eras[0]][layer].xshape\n",
    "    initial_types[layer] = [\n",
    "        ('input', FloatTensorType([None, *shape])),\n",
    "    ]\n",
    "\n",
    "# loop over layers\n",
    "for layer in layers:\n",
    "    store_times[layer] = {}\n",
    "    store_sizes[layer] = {}\n",
    "    model_sizes[layer] = {}\n",
    "    load_times[layer] = {}\n",
    "    run_times[layer] = {}\n",
    "    accuracy[layer] = {}\n",
    "    \n",
    "    # load data\n",
    "    print(f'Preparing data for {layer}...')\n",
    "    df = iotools.read_parquet(input_files[era][layer], verbose=False, batch_size=batch_size, first_batch=0, last_batch=0)\n",
    "    df = df[df['entries']>0]\n",
    "    mes_preprocessed = preprocessors[era][layer].preprocess(df)\n",
    "    if preprocessors is not None:\n",
    "        threshold = 5\n",
    "        mes_preprocessed[mes_preprocessed > threshold] = threshold\n",
    "    if preprocessors is not None:\n",
    "        mes_preprocessed[mes_preprocessed == 0] = 1\n",
    "        \n",
    "    # make raw reconstruction\n",
    "    mes_pred = nmfs[era][layer].predict(mes_preprocessed)\n",
    "    \n",
    "    # loop over points\n",
    "    for point in points:\n",
    "        print(f'Running on layer {layer}, point {point}...')\n",
    "        store_times[layer][point] = []\n",
    "        store_sizes[layer][point] = []\n",
    "        model_sizes[layer][point] = []\n",
    "        load_times[layer][point] = []\n",
    "        run_times[layer][point] = []\n",
    "        accuracy[layer][point] = []\n",
    "        \n",
    "        # loop over repeats\n",
    "        for _ in range(nrepeats):\n",
    "        \n",
    "            # store model in ONNX\n",
    "            start_time = time.time()\n",
    "            nmf_wrapped = NMF2DTransformWrapper(nmfs[era][layer], n_approx_steps = point)\n",
    "            nmf_onnx = convert_sklearn(nmf_wrapped, initial_types=initial_types[layer])\n",
    "            with open(f'test_{layer}.onnx', \"wb\") as f:\n",
    "                f.write(nmf_onnx.SerializeToString())\n",
    "            stop_time = time.time()\n",
    "            store_times[layer][point].append(stop_time - start_time)\n",
    "        \n",
    "            # find model size\n",
    "            store_sizes[layer][point].append(os.path.getsize(f'test_{layer}.onnx') / 1024)\n",
    "        \n",
    "            # load model from ONNX\n",
    "            start_time = time.time()\n",
    "            nmf_onnx = rt.InferenceSession(f\"test_{layer}.onnx\", providers=[\"CPUExecutionProvider\"])\n",
    "            stop_time = time.time()\n",
    "            load_times[layer][point].append(stop_time - start_time)\n",
    "            model_sizes[layer][point].append(sys.getsizeof(nmf_onnx) / 1024)\n",
    "            # (note: not clear if sys.getsizeof is accurate, it might return just the size of some pointers,\n",
    "            #        not the complete size of the total object.)\n",
    "        \n",
    "            # run inference\n",
    "            start_time = time.time()\n",
    "            input_name = nmf_onnx.get_inputs()[0].name\n",
    "            label_name = nmf_onnx.get_outputs()[0].name\n",
    "            mes_pred_onnx = nmf_onnx.run([label_name], {input_name: mes_preprocessed.astype(np.float32)})[0]\n",
    "            stop_time = time.time()\n",
    "            timing = (stop_time - start_time) / len(df)\n",
    "            run_times[layer][point].append(timing)\n",
    "            \n",
    "            # calculate average accuracy per bin per monitoring element\n",
    "            numerator = np.sum(np.abs(mes_pred_onnx - mes_pred))\n",
    "            denominator = len(df) * mes_pred.shape[1] * mes_pred.shape[2]\n",
    "            acc = numerator / denominator\n",
    "            accuracy[layer][point].append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1d8b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "\n",
    "def plot(info, yaxtitle='Time (s)', yaxlog=False):\n",
    "\n",
    "    layers = sorted(list(info.keys()))\n",
    "    points = sorted(list(info[layers[0]].keys()))\n",
    "    \n",
    "    colordict = {\n",
    "        'BPix1': 'navy',\n",
    "        'BPix2': 'royalblue',\n",
    "        'BPix3': 'mediumslateblue',\n",
    "        'BPix4': 'darkorchid'\n",
    "    }\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    for layer in layers:\n",
    "        vals = [info[layer][point] for point in points]\n",
    "        # remove clear outliers\n",
    "        medians = [np.median(v) for v in vals]\n",
    "        iqrs = [(np.quantile(v, 0.75) - np.quantile(v, 0.25)) for v in vals]\n",
    "        for idx, v in enumerate(vals):\n",
    "            vals[idx] = [n for n in v if (n>=medians[idx]-2*iqrs[idx] and n<=medians[idx]+2*iqrs[idx])]\n",
    "        avgs = [np.mean(v) for v in vals]\n",
    "        errs = [np.std(v) for v in vals]\n",
    "        ax.errorbar(points, avgs, yerr=errs, c=colordict[layer], fmt='.')\n",
    "        ax.plot(points, avgs, color=colordict[layer], label=layer, linestyle='--')\n",
    "\n",
    "    ax.set_xscale('log')\n",
    "    if yaxlog: ax.set_yscale('log')\n",
    "        \n",
    "    ax.set_xlabel('Number of approximation steps', fontsize=12)\n",
    "    ax.set_ylabel(yaxtitle, fontsize=12)\n",
    "    ax.grid()\n",
    "    ax.legend(fontsize=12)\n",
    "    \n",
    "    return fig, ax\n",
    "    \n",
    "fig, ax = plot(store_times)\n",
    "ax.text(0, 1.02, 'Model storing time', fontsize=12, transform=ax.transAxes)\n",
    "\n",
    "fig, ax = plot(store_sizes, yaxtitle='Size (kB)')\n",
    "ax.text(0, 1.02, 'Model size on disk', fontsize=12, transform=ax.transAxes)\n",
    "\n",
    "fig, ax = plot(load_times)\n",
    "ax.text(0, 1.02, 'Model loading time', fontsize=12, transform=ax.transAxes)\n",
    "\n",
    "fig, ax = plot(model_sizes, yaxtitle='Size (kB)')\n",
    "ax.text(0, 1.02, 'Model size in memory', fontsize=12, transform=ax.transAxes)\n",
    "\n",
    "fig, ax = plot(run_times)\n",
    "ax.text(0, 1.02, 'Inference time (per instance)', fontsize=12, transform=ax.transAxes)\n",
    "\n",
    "fig, ax = plot(accuracy, yaxtitle='Average per-bin residual', yaxlog=True)\n",
    "ax.text(0, 1.02, 'Model accuracy', fontsize=12, transform=ax.transAxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5727cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
