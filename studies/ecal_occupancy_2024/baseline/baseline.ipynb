{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e3e059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "# external modules\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "\n",
    "# local modules\n",
    "thisdir = os.getcwd()\n",
    "topdir = os.path.abspath(os.path.join(thisdir, '../../../'))\n",
    "sys.path.append(topdir)\n",
    "\n",
    "import tools.iotools as iotools\n",
    "import tools.dftools as dftools\n",
    "import tools.patternfiltering as patternfiltering\n",
    "from tools.dataloadertools import MEDataLoader\n",
    "import studies.ecal_occupancy_2024.preprocessing.preprocessor\n",
    "importlib.reload(studies.ecal_occupancy_2024.preprocessing.preprocessor)\n",
    "from studies.ecal_occupancy_2024.preprocessing.preprocessor import make_default_preprocessor\n",
    "from studies.ecal_occupancy_2024.plotting.plot_cluster_occupancy import plot_cluster_occupancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07cb960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "\n",
    "# settings\n",
    "datadir = '/eos/user/l/llambrec/dialstools-output-test'\n",
    "year = '2024'\n",
    "eras = [\n",
    "    'B-v1',\n",
    "    'C-v1',\n",
    "    'D-v1',\n",
    "    'E-v1',\n",
    "    'E-v2',\n",
    "    #'F-v1',\n",
    "    #'G-v1',\n",
    "    #'H-v1',\n",
    "    #'I-v1',\n",
    "    #'I-v2'\n",
    "]\n",
    "dataset = 'ZeroBias'\n",
    "reco = 'PromptReco'\n",
    "menames = {\n",
    "    'EB': 'EcalBarrel-EBOccupancyTask-EBOT digi occupancy',\n",
    "    #'EE+': 'EcalEndcap-EEOccupancyTask-EEOT digi occupancy EE +',\n",
    "    #'EE-': 'EcalEndcap-EEOccupancyTask-EEOT digi occupancy EE -'\n",
    "}\n",
    "\n",
    "# find files corresponding to settings\n",
    "files = {}\n",
    "for era in eras:\n",
    "    files[era] = {}\n",
    "    for melabel, mename in menames.items():\n",
    "        mainera, version = era.split('-', 1)\n",
    "        f = f'{dataset}-Run{year}{mainera}-{reco}-{version}-DQMIO-{mename}.parquet'\n",
    "        f = os.path.join(datadir, f)\n",
    "        files[era][melabel] = f\n",
    "\n",
    "# existence check\n",
    "missing = []\n",
    "for era, temp in files.items():\n",
    "    for melabel, f in temp.items():\n",
    "        if not os.path.exists(f):\n",
    "            missing.append(f)\n",
    "if len(missing) > 0:\n",
    "    raise Exception(f'The following files do not exist: {missing}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013e19d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to OMS files\n",
    "\n",
    "omsfiles = {}\n",
    "for era in eras:\n",
    "    basedir = '../omsdata'\n",
    "    omsfile = os.path.join(basedir, f'omsdata_Run{year}{era}.json')\n",
    "    if not os.path.exists(omsfile):\n",
    "        print(f'WARNING: OMS file {omsfile} does not exist.')\n",
    "    omsfiles[era] = omsfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83e6ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from studies.pixel_clusters_2024.nmf.nmf_testing_pattern import filter_dfs # make local equivalent later\n",
    "\n",
    "# loop over eras and mes\n",
    "results = {}\n",
    "for melabel, mename in menames.items():\n",
    "    results[melabel] = {}\n",
    "    for era in eras:\n",
    "        print(f'Now processing me {mename}, era {era}...')\n",
    "        \n",
    "        # make dataloader\n",
    "        dataloader = MEDataLoader([files[era][melabel]])\n",
    "        preprocessor_era = 'C-v1'\n",
    "        preprocessor = make_default_preprocessor(preprocessor_era, melabel,\n",
    "                     global_normalization = 'avg',\n",
    "                     local_normalization = 'avg')\n",
    "        \n",
    "        # make loss mask\n",
    "        loss_mask_era = 'C-v1'\n",
    "        loss_mask_file = f'../preprocessing/normdata/zerofrac_Run2024{loss_mask_era}_{melabel}.npy'\n",
    "        loss_mask = np.load(loss_mask_file)\n",
    "        loss_mask = (loss_mask < 0.9).astype(bool)\n",
    "        \n",
    "        # other initializations\n",
    "        flagged_run_numbers = []\n",
    "        flagged_ls_numbers = []\n",
    "        batch_filter_results = []\n",
    "        \n",
    "        # load OMS data\n",
    "        with open(omsfiles[era]) as f:\n",
    "            oms_info = json.load(f)\n",
    "        \n",
    "        # run over batches\n",
    "        batch_size = 10000\n",
    "        batch_params = dataloader.prepare_sequential_batches(batch_size=batch_size)\n",
    "        print(f'Will process {len(batch_params)} batches of size {batch_size}')\n",
    "        for batch_idx, batch_param in enumerate(batch_params):\n",
    "            batch = dataloader.read_sequential_batch(batch_param)\n",
    "            batch_size = len(batch)\n",
    "            print(f'  Loaded batch {batch_idx+1} / {len(batch_params)} with size {batch_size}')\n",
    "            \n",
    "            # filtering\n",
    "            fdict = {melabel: batch}\n",
    "            min_entries = {'EB': 25e3, 'EE+': 2e3, 'EE-': 2e3}\n",
    "            oms_filters = [\n",
    "                ['beams_stable'],\n",
    "                ['cms_active'],\n",
    "                ['ebm_ready'],\n",
    "                ['ebp_ready'],\n",
    "                ['eem_ready'],\n",
    "                ['eep_ready'],\n",
    "                ['esm_ready'],\n",
    "                ['esp_ready'],\n",
    "            ]\n",
    "            mask, filter_results = filter_dfs(fdict,\n",
    "                                     min_entries_filter = min_entries,\n",
    "                                     oms_info = oms_info,\n",
    "                                     oms_filters = oms_filters)\n",
    "            mask = mask.astype(bool)\n",
    "            batch = batch[mask]\n",
    "            batch_size_filtered = len(batch)\n",
    "            print(f'  Found {batch_size_filtered} / {batch_size} instances passing filters.')\n",
    "            if batch_size_filtered==0: continue\n",
    "            \n",
    "            # preprocessing\n",
    "            mes_preprocessed = preprocessor.preprocess(batch)\n",
    "            \n",
    "            # flagging criterion: look for empty regions\n",
    "            patterns = {\n",
    "                'EB': [\n",
    "                    np.zeros((2,2))\n",
    "                ],\n",
    "                'EE+': [np.zeros((2,2))\n",
    "                 ],\n",
    "                'EE-': [\n",
    "                    np.zeros((2,2))\n",
    "                ]\n",
    "            }\n",
    "            flag_empty_regions = patternfiltering.contains_any_pattern(mes_preprocessed, patterns[melabel], mask=loss_mask).astype(bool)\n",
    "            \n",
    "            # flagging criterion: look for regions different from the reference\n",
    "            # (for reference we use just 1 and for the difference we use the ratio, so in practice nothing needs to be done,\n",
    "            #  just define thresholds on the preprocessed MEs)\n",
    "            binary_loss = np.logical_or(mes_preprocessed < 0.2, mes_preprocessed > 5)\n",
    "            # do time correction\n",
    "            window_size = 3\n",
    "            binary_loss = sp.ndimage.convolve1d(binary_loss, np.ones(window_size)/window_size, axis=0)\n",
    "            binary_loss = (binary_loss == 1)\n",
    "            patterns = {\n",
    "                'EB': [\n",
    "                    np.ones((2,2))\n",
    "                ],\n",
    "                'EE+': [\n",
    "                    np.ones((2,2))\n",
    "                ],\n",
    "                'EE-': [\n",
    "                    np.ones((2,2))\n",
    "                ]\n",
    "            }\n",
    "            flag_extrema = patternfiltering.contains_any_pattern(binary_loss, patterns[melabel], mask=loss_mask).astype(bool)\n",
    "            \n",
    "            # todo: add more\n",
    "            \n",
    "            # combine criteria\n",
    "            flags = (\n",
    "                (flag_empty_regions) |\n",
    "                (flag_extrema)\n",
    "            )\n",
    "            \n",
    "            # store flagged lumisections\n",
    "            flagged_run_numbers_batch = batch['run_number'].values[flags]\n",
    "            flagged_ls_numbers_batch = batch['ls_number'].values[flags]\n",
    "            n_unique_runs = len(np.unique(flagged_run_numbers_batch))\n",
    "            print(f'    -> Found {np.sum(flags.astype(int))} flagged lumisections in {n_unique_runs} runs.')\n",
    "            \n",
    "            # add to results\n",
    "            flagged_run_numbers.append(flagged_run_numbers_batch)\n",
    "            flagged_ls_numbers.append(flagged_ls_numbers_batch)\n",
    "            batch_filter_results.append(filter_results)\n",
    "            \n",
    "        # contatenate the results from the batches\n",
    "        filter_results = {}\n",
    "        if len(batch_filter_results)>0:\n",
    "            for key in batch_filter_results[0].keys():\n",
    "                filter_results[key] = sum([batch_filter_result[key] for batch_filter_result in batch_filter_results], [])\n",
    "        if len(flagged_run_numbers) > 0:\n",
    "            flagged_run_numbers = np.concatenate(flagged_run_numbers)\n",
    "            flagged_ls_numbers = np.concatenate(flagged_ls_numbers)\n",
    "        else:\n",
    "            flagged_run_numbers = np.array([])\n",
    "            flagged_ls_numbers = np.array([])\n",
    "        \n",
    "        # add to dict\n",
    "        results[melabel][era] = {\n",
    "            'flagged_run_numbers': flagged_run_numbers,\n",
    "            'flagged_ls_numbers': flagged_ls_numbers,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232b99c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print flagged lumisections\n",
    "\n",
    "for melabel, mename in menames.items():\n",
    "    print(f'Results for {melabel}:')\n",
    "    for era in eras:\n",
    "        flagged_run_numbers = results[melabel][era]['flagged_run_numbers']\n",
    "        flagged_ls_numbers = results[melabel][era]['flagged_ls_numbers']\n",
    "        print(f'  Flagged lumisections in era {era} ({len(flagged_run_numbers)}):')\n",
    "        for run, ls in zip(flagged_run_numbers, flagged_ls_numbers):\n",
    "            print(f'    Run {run}, LS {ls}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527d8bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data for plotting some random (or not random) examples\n",
    "\n",
    "# random lumisections\n",
    "nplot = 0\n",
    "#random_ids = np.random.choice(len(available_run_numbers), size=min(nplot, len(available_run_numbers)), replace=False)\n",
    "#selected_run_numbers = available_run_numbers[random_ids]\n",
    "#selected_ls_numbers = available_ls_numbers[random_ids]\n",
    "#random_ids = np.random.choice(len(flagged_run_numbers), size=min(nplot, len(flagged_run_numbers)), replace=False)\n",
    "#selected_run_numbers = flagged_run_numbers[random_ids]\n",
    "#selected_ls_numbers = flagged_ls_numbers[random_ids]\n",
    "\n",
    "# alternative: specific selected lumisections\n",
    "era = 'E-v1'\n",
    "selected_runlumis = [(381151, 320)]\n",
    "selected_run_numbers = [el[0] for el in selected_runlumis]\n",
    "selected_ls_numbers = [el[1] for el in selected_runlumis]\n",
    "\n",
    "if len(selected_run_numbers) > 0:\n",
    "    \n",
    "    # calculate random indices and load data\n",
    "    print('Loading data...')\n",
    "    dfs = {}\n",
    "    mes = {}\n",
    "    for melabel, mename in menames.items():\n",
    "        dfs[melabel] = iotools.read_lumisections(files[era][melabel], selected_run_numbers, selected_ls_numbers, mode='batched')\n",
    "        mes[melabel], runs, lumis = dftools.get_mes(dfs[melabel], xbinscolumn='x_bin', ybinscolumn='y_bin', runcolumn='run_number', lumicolumn='ls_number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb01832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot examples\n",
    "\n",
    "import studies.ecal_occupancy_2024.plotting.plot_cluster_occupancy\n",
    "importlib.reload(studies.ecal_occupancy_2024.plotting.plot_cluster_occupancy)\n",
    "from studies.ecal_occupancy_2024.plotting.plot_cluster_occupancy import plot_cluster_occupancy\n",
    "\n",
    "if len(selected_run_numbers) > 0:\n",
    "    \n",
    "    # make loss mask\n",
    "    loss_mask_era = 'C-v1'\n",
    "    loss_mask_file = f'../preprocessing/normdata/zerofrac_Run2024{loss_mask_era}_{melabel}.npy'\n",
    "    loss_mask = np.load(loss_mask_file)\n",
    "    loss_mask = (loss_mask < 0.9).astype(bool)\n",
    "    \n",
    "    # preprocess\n",
    "    print('Processing...')\n",
    "    mes_preprocessed = {}\n",
    "    mes_pred = {}\n",
    "    losses = {}\n",
    "    for melabel, mename in mes.items():\n",
    "        preprocessor_era = 'C-v1'\n",
    "        preprocessor = make_default_preprocessor(preprocessor_era, melabel,\n",
    "                         global_normalization = 'avg',\n",
    "                         local_normalization = 'avg')\n",
    "        mes_preprocessed[melabel] = preprocessor.preprocess(dfs[melabel])\n",
    "        \n",
    "    # calculate binary loss\n",
    "    binary_losses = {}\n",
    "    for melabel, mename in mes.items():\n",
    "        binary_loss = np.logical_or(mes_preprocessed[melabel] < 0.2, mes_preprocessed[melabel] > 5)\n",
    "        binary_loss = np.multiply(binary_loss, loss_mask[np.newaxis, :, :])\n",
    "        binary_losses[melabel] = binary_loss\n",
    "        \n",
    "    # make the plots\n",
    "    print('Plotting...')\n",
    "    for idx in range(len(selected_run_numbers)):\n",
    "        run = runs[idx]\n",
    "        lumi = lumis[idx]\n",
    "        for melabel, mename in menames.items():\n",
    "            me_orig = mes[melabel][idx, :, :]\n",
    "            me_preprocessed = mes_preprocessed[melabel][idx, :, :]\n",
    "            binary_loss = binary_losses[melabel][idx, :, :]\n",
    "    \n",
    "            # initialize figure\n",
    "            fig, axs = plt.subplots(ncols=3, nrows=1, figsize=(18, 6), squeeze=False)\n",
    "            \n",
    "            # plot raw data\n",
    "            fig, axs[0, 0] = plot_cluster_occupancy(me_orig, fig=fig, ax=axs[0, 0],\n",
    "                   title='Raw', titlesize=15,\n",
    "                   xaxtitlesize=15, yaxtitlesize=15,\n",
    "                   ticklabelsize=12, colorticklabelsize=12,\n",
    "                   docolorbar=True, caxtitle='Digi occupancy',\n",
    "                   caxtitlesize=15, caxtitleoffset=15)\n",
    "        \n",
    "            # plot preprocessed\n",
    "            fig, axs[0, 1] = plot_cluster_occupancy(me_preprocessed, fig=fig, ax=axs[0, 1],\n",
    "                   title='Input', titlesize=15,\n",
    "                   xaxtitlesize=15, yaxtitlesize=15,\n",
    "                   ticklabelsize=12, colorticklabelsize=12,\n",
    "                   docolorbar=True, caxtitle='Digi occupancy\\n(normalized)',\n",
    "                   caxrange=(1e-6,2),\n",
    "                   caxtitlesize=15, caxtitleoffset=30)\n",
    "            \n",
    "            # plot binary loss\n",
    "            fig, axs[0, 2] = plot_cluster_occupancy(binary_loss, fig=fig, ax=axs[0, 2],\n",
    "                   title='Binary loss', titlesize=15,\n",
    "                   xaxtitlesize=15, yaxtitlesize=15,\n",
    "                   ticklabelsize=12, colorticklabelsize=12,\n",
    "                   docolorbar=True, caxtitle='Loss',\n",
    "                   caxrange=(1e-6, 1),\n",
    "                   caxtitlesize=15, caxtitleoffset=30)\n",
    "                \n",
    "            # plot aesthetics\n",
    "            plt.subplots_adjust(wspace=0.55)\n",
    "            title = f'Run {run}, LS {lumi}, ECAL {melabel}'\n",
    "            axs[0, 0].text(0.01, 1.3, title, fontsize=15, transform=axs[0, 0].transAxes)\n",
    "            plt.show()\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae24d92a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
