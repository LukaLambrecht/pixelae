{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d26fa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "\n",
    "# external modules\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "from fnmatch import fnmatch\n",
    "import importlib\n",
    "\n",
    "# local modules\n",
    "thisdir = os.getcwd()\n",
    "topdir = os.path.abspath(os.path.join(thisdir, '../../'))\n",
    "sys.path.append(topdir)\n",
    "\n",
    "import tools.iotools as iotools\n",
    "import tools.dftools as dftools\n",
    "import tools.omsapi.get_oms_data as oms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7e7060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the omsapi instance\n",
    "\n",
    "omsapi = oms.get_oms_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f66143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define run ranges\n",
    "\n",
    "# references:\n",
    "# - https://twiki.cern.ch/twiki/bin/view/CMS/PdmVRun3Analysis#2024_Era_definition\n",
    "\n",
    "eradict = {\n",
    "  'Run2024A-v1': (378142, 378970),\n",
    "  'Run2024B-v1': (378971, 379411),\n",
    "  'Run2024C-v1': (379412, 380252),\n",
    "  'Run2024D-v1': (380253, 380947),\n",
    "  'Run2024E-v1': (380948, 381383),\n",
    "  'Run2024E-v2': (381384, 381943),\n",
    "  'Run2024F-v1': (381944, 383779),\n",
    "  'Run2024G-v1': (383780, 385813),\n",
    "  'Run2024H-v1': (385814, 386408),\n",
    "  'Run2024I-v1': (386409, 386797),\n",
    "  'Run2024I-v2': (386798, 387121),\n",
    "  'Run2024J-v1': (387203, 387721)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce18b7b2",
   "metadata": {},
   "source": [
    "**Part 1: pileup, luminosity, and similar attributes per lumisection**\n",
    "\n",
    "This does not include HLT trigger rates, which are retrieved separately in part 2 further down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b3700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out which attributes are available per lumisection\n",
    "\n",
    "runnb = 378142 # dummy run, should not matter\n",
    "ls_info = oms.get_oms_data( omsapi, 'lumisections', runnb )\n",
    "available_attributes = list(oms.get_oms_response_attributes(ls_info))\n",
    "print(available_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fab5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define attributes to retrieve\n",
    "\n",
    "attributes = [\n",
    "    'delivered_lumi_per_lumisection',\n",
    "    'recorded_lumi_per_lumisection',\n",
    "    'pileup',\n",
    "    'physics_flag',\n",
    "    'fill_number',\n",
    "    'run_number',\n",
    "    'lumisection_number',\n",
    "]\n",
    "\n",
    "# quick check\n",
    "for attribute in attributes:\n",
    "    if attribute not in available_attributes:\n",
    "        print(f'WARNING: attribute {attribute} does not seem to be available.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cfd667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data from OMS\n",
    "\n",
    "importlib.reload(oms)\n",
    "info = {}\n",
    "for era, runrange in eradict.items():\n",
    "    print('Retrieving data for era {}'.format(era))\n",
    "    ls_info = oms.get_oms_data_iterative(omsapi, 'lumisections', runrange, attributes)\n",
    "    print('Found {} lumisections'.format(len(ls_info[list(ls_info.keys())[0]])))\n",
    "    info[era] = ls_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfc0494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ad-hoc fix for observed None values in physics flag\n",
    "\n",
    "for era in eradict.keys():\n",
    "    thisinfo = info[era]['physics_flag']\n",
    "    nnone = thisinfo.count(None)\n",
    "    if nnone==0: continue\n",
    "    print('Found {} None instances (out of {} total) for era {}'.format(nnone, len(thisinfo), era))\n",
    "    info[era]['physics_flag'] = [el if el is not None else False for el in thisinfo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d951e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: filter out runs that are not in the DQMIO data\n",
    "#           (for smaller files and cleaner plots)\n",
    "\n",
    "# define settings for which files to retrieve the run numbers from\n",
    "datadir = '/eos/user/l/llambrec/dialstools-output'\n",
    "dataset = 'ZeroBias'\n",
    "reco = 'PromptReco'\n",
    "me = 'PixelPhase1-Phase1_MechanicalView-PXBarrel-clusters_per_SignedModuleCoord_per_SignedLadderCoord_PXLayer_1'\n",
    "\n",
    "# find files corresponding to settings\n",
    "filepattern = f'{dataset}-Run*-{reco}-*-DQMIO-{me}.parquet'\n",
    "files = sorted([os.path.join(datadir, f) for f in os.listdir(datadir) if fnmatch(f, filepattern)])\n",
    "\n",
    "# retrieve run numbers\n",
    "allruns = []\n",
    "print(f'Reading {len(files)} files for retrieving run numbers...')\n",
    "for f in files:\n",
    "    df = iotools.read_parquet(f, columns=['run_number'])\n",
    "    run_numbers = dftools.get_runs(df, runcolumn='run_number')\n",
    "    allruns += run_numbers\n",
    "allruns = sorted(list(set(allruns)))\n",
    "allruns = np.array(allruns).astype(int)\n",
    "print(f'Found {len(allruns)} runs.')\n",
    "\n",
    "# do filtering\n",
    "for era in eradict.keys():\n",
    "    print(f'Filtering era {era}...')\n",
    "    runnbs = np.array(info[era]['run_number']).astype(int)\n",
    "    unique_runnbs = np.unique(runnbs)\n",
    "    run_mask = np.isin(unique_runnbs, allruns).astype(bool)\n",
    "    ls_mask = np.isin(runnbs, allruns).astype(bool)\n",
    "    print(f'Keeping {np.sum(run_mask)} / {len(run_mask)} runs and {np.sum(ls_mask)} / {len(ls_mask)} lumisections.')\n",
    "    for attribute in info[era].keys():\n",
    "        info[era][attribute] = [info[era][attribute][idx] for idx in range(len(info[era][attribute])) if ls_mask[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e4919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to json files\n",
    "\n",
    "outputdir = 'omsdata'\n",
    "if not os.path.exists(outputdir): os.makedirs(outputdir)\n",
    "    \n",
    "for era in eradict.keys():\n",
    "    thisinfo = info[era]\n",
    "    outputfile = os.path.join(outputdir, 'omsdata_{}.json'.format(era))\n",
    "    with open(outputfile, 'w') as f:\n",
    "        json.dump(thisinfo, f)\n",
    "    print(f'Created file {outputfile}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7550ed",
   "metadata": {},
   "source": [
    "**Part 2: HLT trigger rates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bf70c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all runs that are actually present in the DQMIO data,\n",
    "# rather than all runs present in the OMS database.\n",
    "# (this is done to drastically reduce the number of OMS API calls that are made.)\n",
    "\n",
    "# define settings for which files to retrieve the run numbers from\n",
    "datadir = '/eos/user/l/llambrec/dialstools-output'\n",
    "dataset = 'ZeroBias'\n",
    "reco = 'PromptReco'\n",
    "me = 'PixelPhase1-Phase1_MechanicalView-PXBarrel-clusters_per_SignedModuleCoord_per_SignedLadderCoord_PXLayer_1'\n",
    "\n",
    "# find files corresponding to settings\n",
    "filepattern = f'{dataset}-Run*-{reco}-*-DQMIO-{me}.parquet'\n",
    "files = sorted([os.path.join(datadir, f) for f in os.listdir(datadir) if fnmatch(f, filepattern)])\n",
    "\n",
    "# retrieve run numbers\n",
    "allruns = []\n",
    "print(f'Reading {len(files)} files for retrieving run numbers...')\n",
    "for f in files:\n",
    "    df = iotools.read_parquet(f, columns=['run_number'])\n",
    "    run_numbers = dftools.get_runs(df, runcolumn='run_number')\n",
    "    allruns += run_numbers\n",
    "allruns = sorted(list(set(allruns)))\n",
    "print(f'Found {len(allruns)} runs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e893724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get available HLT paths and attributes\n",
    "\n",
    "# pick a dummy run\n",
    "# note: the trigger menu changes over time, so the returned values might change depending on the chosen run.\n",
    "#       however, it is assumed that for the triggers of interest, only the version number changes.\n",
    "runnb = 378142\n",
    "ls_info = oms.get_oms_data( omsapi, 'hltpathinfo', runnb=runnb, attributes=['path_name'] )\n",
    "hltpaths = oms.get_oms_response_attribute(ls_info, 'path_name')\n",
    "#hltpaths = [p for p in hltpaths if p.startswith('HLT_ZeroBias')]\n",
    "print('Available triggers:')\n",
    "for p in hltpaths: print('  {}'.format(p))\n",
    "\n",
    "# pick a trigger from the list above\n",
    "trigger = 'DQM_PixelReconstruction_v8'\n",
    "path_filter = {'attribute_name':'path_name', 'value':trigger, 'operator':'EQ'}\n",
    "per_lumi_arg = {'group[granularity]': 'lumisection'}\n",
    "ls_info_raw = oms.get_oms_data(omsapi, 'hltpathrates', runnb, extraargs=per_lumi_arg, extrafilters=[path_filter])\n",
    "print('Available attributes')\n",
    "print(oms.get_oms_response_attributes(ls_info_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ad8e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the HLT rate from OMS\n",
    "# note: only works for filtering per run, not run ranges.\n",
    "# note: write one json file per run rather than per era,\n",
    "#       so that nothing is lost if this cell crashes somewhere in the middle of an era.\n",
    "#       the per-run json files will combined into one per era in the cell below.\n",
    "# note: works in principle, but did not yet run for all eras as it takes too long.\n",
    "#       try filtering based on pileup or lumi first, and return to trigger rates if needed.\n",
    "\n",
    "trigger_patterns = [\n",
    "    'HLT_Physics_v*',\n",
    "    'HLT_ZerioBias_v*',\n",
    "    'DQM_PixelReconstruction_v*'\n",
    "]\n",
    "\n",
    "attributes = [\n",
    "    'rate',\n",
    "    'first_lumisection_number',\n",
    "    'run_number'\n",
    "]\n",
    "\n",
    "# note: the attribute 'first_lumisection_number' actually corresponds to the lumisection number\n",
    "#       when the rates are retrieved per lumisection.\n",
    "\n",
    "outputdir = 'omsdata'\n",
    "if not os.path.exists(outputdir): os.makedirs(outputdir)\n",
    "\n",
    "for era, runrange in eradict.items():\n",
    "    print('Retrieving data for era {}'.format(era))\n",
    "    info = {}\n",
    "    # get a list of runs\n",
    "    runs = oms.get_oms_data( omsapi, 'runs', runnb=runrange, attributes=['run_number'] )\n",
    "    runs = oms.get_oms_response_attribute(runs, 'run_number')\n",
    "    # filter on the runs actually present in the DQMIO data\n",
    "    filtered_runs = [r for r in runs if r in allruns]\n",
    "    print('Found {} runs in OMS, of which {} are in the DQMIO files.'.format(len(runs), len(filtered_runs)))\n",
    "    runs = filtered_runs\n",
    "    print('Looping over {} runs...'.format(len(runs)))\n",
    "    # loop over runs\n",
    "    for run in runs:\n",
    "        info[run] = {}\n",
    "        # get the trigger names for this run\n",
    "        hltinfo = oms.get_oms_data( omsapi, 'hltpathinfo', runnb=run, attributes=['path_name'], limit_entries=10000 )\n",
    "        hltpaths = oms.get_oms_response_attribute(hltinfo, 'path_name')\n",
    "        triggers = []\n",
    "        for hltpath in hltpaths:\n",
    "            keep = False\n",
    "            for pattern in trigger_patterns:\n",
    "                if fnmatch(hltpath, pattern): keep = True\n",
    "            if keep: triggers.append(hltpath)\n",
    "        print('Run {}: found following triggers: {}'.format(run, triggers))\n",
    "        # loop over trigger names\n",
    "        for trigger in triggers:\n",
    "            path_filter = {'attribute_name':'path_name','value':trigger,'operator':'EQ'}\n",
    "            per_lumi_arg = {'group[granularity]':'lumisection'}\n",
    "            ls_info_raw = oms.get_oms_data( omsapi, 'hltpathrates', runnb=run, attributes=attributes,\n",
    "                                extraargs=per_lumi_arg, extrafilters=[path_filter], limit_entries=10000 )\n",
    "            rate = {attribute: oms.get_oms_response_attribute(ls_info_raw, attribute) for attribute in attributes}\n",
    "            info[run][trigger] = rate\n",
    "            \n",
    "        # store the information for this run\n",
    "        # note: keep in loop to avoid losing everything over a transient issue.\n",
    "        outputfile = os.path.join(outputdir, 'hltrate_{}_{}.json'.format(era, run))\n",
    "        with open(outputfile, 'w') as f:\n",
    "            json.dump(info[run], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56acbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the per-run json files with HLT rates into per-era files\n",
    "\n",
    "for era, runrange in eradict.items():\n",
    "    # set input and output files\n",
    "    inputfiles = sorted([os.path.join(outputdir, f) for f in os.listdir(outputdir)\n",
    "                   if fnmatch(f, f'hltrate_{era}_??????.json')])\n",
    "    if len(inputfiles)==0:\n",
    "        print(f'WARNING: no input files found for era {era}, skipping.')\n",
    "        continue\n",
    "    outputfile = os.path.join(outputdir, f'hltrate_{era}.json')\n",
    "    hltrates = {}\n",
    "    for inputfile in inputfiles:\n",
    "        run = int(inputfile.split('_')[-1].replace('.json', ''))\n",
    "        with open(inputfile, 'r') as f:\n",
    "            info = json.load(f)\n",
    "        hltrates[run] = info\n",
    "    with open(outputfile, 'w') as f:\n",
    "        json.dump(hltrates, f)\n",
    "    print(f'Merged {len(inputfiles)} into {outputfile}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d283af50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
