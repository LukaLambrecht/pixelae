{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba276aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "thisdir = os.getcwd()\n",
    "topdir = os.path.abspath(os.path.join(thisdir, '../../../'))\n",
    "sys.path.append(topdir)\n",
    "\n",
    "import tools.iotools as iotools\n",
    "import tools.dftools as dftools\n",
    "import plotting.plottools as plottools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5987015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to files\n",
    "\n",
    "# load occupancy from dqmio files\n",
    "\n",
    "mes = ({\n",
    "    'PXLayer_1': 'PixelPhase1-Phase1_MechanicalView-PXBarrel-clusters_per_SignedModuleCoord_per_SignedLadderCoord_PXLayer_1',\n",
    "    'PXLayer_2': 'PixelPhase1-Phase1_MechanicalView-PXBarrel-clusters_per_SignedModuleCoord_per_SignedLadderCoord_PXLayer_2',\n",
    "    #'PXLayer_3': 'PixelPhase1-Phase1_MechanicalView-PXBarrel-clusters_per_SignedModuleCoord_per_SignedLadderCoord_PXLayer_3',\n",
    "    #'PXLayer_4': 'PixelPhase1-Phase1_MechanicalView-PXBarrel-clusters_per_SignedModuleCoord_per_SignedLadderCoord_PXLayer_4',\n",
    "})\n",
    "\n",
    "eras = [\n",
    "  #'Run2024A-v1', # only commissioning, no lumisections with physics flag set to True\n",
    "  'Run2024B-v1',\n",
    "  'Run2024C-v1',\n",
    "  'Run2024D-v1',\n",
    "  'Run2024E-v1',\n",
    "  'Run2024E-v2',\n",
    "  'Run2024F-v1',\n",
    "  'Run2024G-v1',\n",
    "  'Run2024H-v1',\n",
    "  'Run2024I-v1',\n",
    "  'Run2024I-v2',\n",
    "  #'Run2024J-v1'  # pp reference run for heavy ion run; lower pileup and occupancy\n",
    "]\n",
    "\n",
    "datadir = '/eos/user/l/llambrec/dialstools-output'\n",
    "year = '2024'\n",
    "dataset = 'ZeroBias'\n",
    "reco = 'PromptReco'\n",
    "\n",
    "files = {}\n",
    "for era in eras:\n",
    "    files[era] = {}\n",
    "    for melabel, mename in mes.items():\n",
    "        mainera, version = era.split('-')\n",
    "        f = f'{dataset}-{mainera}-{reco}-{version}-DQMIO-{mename}.parquet'\n",
    "        f = os.path.join(datadir, f)\n",
    "        files[era][melabel] = f\n",
    "\n",
    "# existence check\n",
    "missing = []\n",
    "for era in eras:\n",
    "    for melabel in mes.keys():\n",
    "        f = files[era][melabel]\n",
    "        if not os.path.exists(f):\n",
    "            missing.append(f)\n",
    "if len(missing) > 0:\n",
    "    raise Exception(f'The following files do not exist: {missing}')\n",
    "else:\n",
    "    print(f'Found {len(files)} files.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e759e69",
   "metadata": {},
   "source": [
    "**Part 1: calculate norm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81190f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average per era and per ME\n",
    "\n",
    "outputdir = 'normdata'\n",
    "if not os.path.exists(outputdir): os.makedirs(outputdir)\n",
    "    \n",
    "doplot = True\n",
    "dosave = True\n",
    "\n",
    "for melabel, mename in mes.items():\n",
    "    for era in eras:\n",
    "        print(f'Now running on era {era}, ME {melabel}...')\n",
    "        f = files[era][melabel]\n",
    "        \n",
    "        # read number of instances in this era\n",
    "        dummy = iotools.read_parquet(f, columns=['run_number'])\n",
    "        nlumis = len(dummy)\n",
    "        print(f'Found {nlumis} lumisections in this era.')\n",
    "        \n",
    "        # split in batches\n",
    "        batch_size = 5000\n",
    "        num_batches = int((nlumis-1)/batch_size)+1\n",
    "        batch_sums = []\n",
    "        batch_counts = []\n",
    "        for batchidx in range(num_batches):\n",
    "            print(f'  - Extracting batch {batchidx+1} / {num_batches}...')\n",
    "            \n",
    "            # get batch\n",
    "            df = iotools.read_parquet(f, batch_size=batch_size, first_batch=batchidx, last_batch=batchidx)\n",
    "            \n",
    "            # do filtering\n",
    "            df = df[df['entries'] > 0]\n",
    "            print(f'    Found {len(df)} entries in batch passing filters.')\n",
    "            if len(df)==0: continue\n",
    "                \n",
    "            me_array, _, _ = dftools.get_mes(df, xbinscolumn='x_bin', ybinscolumn='y_bin', runcolumn='run_number', lumicolumn='ls_number')\n",
    "            print(f'    Found array of shape {me_array.shape}')\n",
    "            \n",
    "            # get sum\n",
    "            threshold = 1000\n",
    "            mesum = np.sum(me_array, axis=0, where=(me_array > threshold))\n",
    "            batch_sums.append(mesum)\n",
    "            #mecounts = np.count_nonzero(me_array > 1000, axis=0)\n",
    "            # note: not sure anymore what the above (with threshold 1000) was intended for,\n",
    "            #       but in any case it seems unsuitable for layer 2, 3 and 4 (maybe ok for layer 1?).\n",
    "            #       now rerunning for for layer 3 and 4 without this threshold, but not yet for layer 1 and 2,\n",
    "            #       as I already have results for those and I first want to just add layer 3 and 4.\n",
    "            #       maybe later also rerun for layer 1 and 2.\n",
    "            # note: looking back at it, probably the threshold should have been applied to both the sum and the count\n",
    "            #       (to avoid being impacted by transient zero- or low-occupancy bins),\n",
    "            #       but it seems like it was only applied to the count, resulting in a distorted mean distribution.\n",
    "            mecounts = np.count_nonzero(me_array > threshold, axis=0)\n",
    "            batch_counts.append(mecounts)\n",
    "            \n",
    "            # explicitly delete some variables for memory saving\n",
    "            del df\n",
    "            del me_array\n",
    "            \n",
    "        # make total normalized sum over batches\n",
    "        mesum = np.sum(np.array(batch_sums), axis=0)\n",
    "        mesum = mesum / np.mean(mesum)\n",
    "        # set small but nonzero values to zero for stability\n",
    "        mesum[mesum < 0.05] = 0\n",
    "        \n",
    "        # calculate total per-bin nonzero counts\n",
    "        mecounts = np.sum(np.array(batch_counts), axis=0)\n",
    "        mecounts = np.where(mecounts==0, 1, mecounts)\n",
    "        \n",
    "        # calculate normalized per-bin averaged value\n",
    "        avgme = np.divide(mesum, mecounts)\n",
    "        avgme = avgme / np.mean(avgme)\n",
    "        # set small values to zero (so they will be automatically masked)\n",
    "        avgme[avgme < 0.05] = 0\n",
    "        \n",
    "        # plot result\n",
    "        if doplot:\n",
    "            '''title = mename.split('-')[-1]+ '\\n' + f'Era {era} normalized sum'\n",
    "            fig, ax = plottools.plot_hist_2d(mesum, figsize=(12,6), title=title, titlesize=15,\n",
    "                xaxtitle=None, xaxtitlesize=None, yaxtitle=None, yaxtitlesize=None,\n",
    "                ticklabelsize=12, colorticklabelsize=12, extent=None, aspect=None,\n",
    "                docolorbar=True, caxtitle='Number of clusters', caxrange=(1e-6, 2), caxtitlesize=15, caxtitleoffset=15,\n",
    "                origin='lower')\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        \n",
    "            title = mename.split('-')[-1]+ '\\n' + f'Era {era} nonzero counts'\n",
    "            fig, ax = plottools.plot_hist_2d(mecounts, figsize=(12,6), title=title, titlesize=15,\n",
    "                xaxtitle=None, xaxtitlesize=None, yaxtitle=None, yaxtitlesize=None,\n",
    "                ticklabelsize=12, colorticklabelsize=12, extent=None, aspect=None,\n",
    "                docolorbar=True, caxtitle='Number of clusters', caxtitlesize=15, caxtitleoffset=15,\n",
    "                caxrange = (1e-6, 10), # temp for testing\n",
    "                origin='lower')\n",
    "            plt.show()\n",
    "            plt.close()'''\n",
    "        \n",
    "            title = mename.split('-')[-1]+ '\\n' + f'Era {era} normalized mean'\n",
    "            fig, ax = plottools.plot_hist_2d(avgme, figsize=(12,6), title=title, titlesize=15,\n",
    "                xaxtitle=None, xaxtitlesize=None, yaxtitle=None, yaxtitlesize=None,\n",
    "                ticklabelsize=12, colorticklabelsize=12, extent=None, aspect=None,\n",
    "                docolorbar=True, caxtitle='Number of clusters', caxrange=(1e-6, 2), caxtitlesize=15, caxtitleoffset=15,\n",
    "                origin='lower')\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        \n",
    "        # save array\n",
    "        if dosave:\n",
    "            outputfile = f'avgme_{era}_{melabel}.npy'\n",
    "            outputfile = os.path.join(outputdir, outputfile)\n",
    "            np.save(outputfile, avgme)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4e3a90",
   "metadata": {},
   "source": [
    "**Part 2: plot result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d1be4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdir = 'normdata'\n",
    "    \n",
    "for melabel, mename in mes.items():\n",
    "    for era in eras:\n",
    "        \n",
    "        # load array\n",
    "        f = f'avgme_{era}_{melabel}.npy'\n",
    "        f = os.path.join(outputdir, f)\n",
    "        avgme = np.load(f)\n",
    "        \n",
    "        # plot result\n",
    "        title = mename.split('-')[-1]+ '\\n' + f'Era {era} mean'\n",
    "        fig, ax = plottools.plot_hist_2d(avgme, figsize=(12,6), title=title, titlesize=15,\n",
    "                xaxtitle=None, xaxtitlesize=None, yaxtitle=None, yaxtitlesize=None,\n",
    "                ticklabelsize=12, colorticklabelsize=12, extent=None, aspect=None,\n",
    "                docolorbar=True, caxtitle='Number of clusters', caxrange=(1e-6, 2), caxtitlesize=15, caxtitleoffset=15,\n",
    "                origin='lower')\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc842265",
   "metadata": {},
   "source": [
    "**Part 3: some more advanced plotting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302e90a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdir = 'normdata'\n",
    "\n",
    "res = {}\n",
    "\n",
    "for melabel, mename in mes.items():\n",
    "    for era in eras:\n",
    "        res[era] = {}\n",
    "        \n",
    "        # load array\n",
    "        f = f'avgme_{era}_{melabel}.npy'\n",
    "        f = os.path.join(outputdir, f)\n",
    "        avgme = np.load(f)\n",
    "        \n",
    "        # average over y-axis\n",
    "        nladders = int((avgme.shape[0] - 2) / 4)\n",
    "        ids_far = np.concatenate((np.arange(start=0, stop=2*nladders, step=4), np.arange(start=2*nladders+2, stop=4*nladders+1, step=4)))\n",
    "        ids_far = np.sort(np.concatenate((ids_far, ids_far+1)))\n",
    "        mask_far = np.zeros(avgme.shape[0]).astype(bool)\n",
    "        mask_far[ids_far] = True\n",
    "        ids_close = np.concatenate((np.arange(start=2, stop=2*nladders, step=4), np.arange(start=2*nladders+4, stop=4*nladders+1, step=4)))\n",
    "        ids_close = np.sort(np.concatenate((ids_close, ids_close+1)))\n",
    "        mask_close = np.zeros(avgme.shape[0]).astype(bool)\n",
    "        mask_close[ids_close] = True\n",
    "        # approach 1, with mean\n",
    "        #avgme_far = np.mean(avgme[mask_far, :], axis=0)\n",
    "        #avgme_close = np.mean(avgme[mask_close, :], axis=0)\n",
    "        # approach 2, with median\n",
    "        avgme_far = np.quantile(avgme[mask_far, :], 0.5, axis=0)\n",
    "        avgme_close = np.quantile(avgme[mask_close, :], 0.5, axis=0)\n",
    "        res[era]['far'] = avgme_far\n",
    "        res[era]['close'] = avgme_close\n",
    "        \n",
    "    # make a plot\n",
    "    fig, axs = plt.subplots(ncols=3, figsize=(15, 6))\n",
    "    cmap = mpl.colormaps.get_cmap('jet')\n",
    "    colors = [cmap(f) for f in np.linspace(0, 1, num=len(eras))]\n",
    "    for idx, era in enumerate(eras):\n",
    "        axs[0].plot(res[era]['far'], color='b')\n",
    "        axs[0].plot(res[era]['close'], color='r')\n",
    "        axs[1].plot(res[era]['far'], color=colors[idx])\n",
    "        axs[2].plot(res[era]['close'], color=colors[idx])\n",
    "    axs[1].set_ylim((0.7, 2.5))\n",
    "    axs[2].set_ylim((0.7, 2.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8191e68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
