{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3bc931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import joblib\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "thisdir = os.getcwd()\n",
    "topdir = os.path.abspath(os.path.join(thisdir, '../../../'))\n",
    "sys.path.append(topdir)\n",
    "\n",
    "import tools.iotools as iotools\n",
    "import tools.dftools as dftools\n",
    "import plotting.plottools as plottools\n",
    "from tools.dataloadertools import MEDataLoader\n",
    "\n",
    "from studies.clusters_2024.preprocessing.preprocessor import make_default_preprocessor\n",
    "from studies.clusters_2024.nmf.modeldefs.nmf2d import NMF2D\n",
    "from studies.clusters_2024.nmf.nmf_training import find_files, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a1c0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to files\n",
    "\n",
    "layer = 1\n",
    "files = find_files(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d36577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define eras to use in training\n",
    "\n",
    "eras = [\n",
    "    #'A-v1',\n",
    "    #'B-v1',\n",
    "    #'C-v1',\n",
    "    #'D-v1',\n",
    "    #'E-v1',\n",
    "    #'E-v2',\n",
    "    #'F-v1',\n",
    "    'F-v1-part3'\n",
    "    #'G-v1',\n",
    "    #'H-v1',\n",
    "    #'I-v1',\n",
    "    #'I-v2',\n",
    "    #'J-v1'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c902b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make preprocessors for the corresponding eras\n",
    "\n",
    "preprocessors = {}\n",
    "for era in eras:\n",
    "    preprocessor_era = era\n",
    "    if '-part' in preprocessor_era: preprocessor_era = era.split('-part')[0]\n",
    "    preprocessors[era] = make_default_preprocessor(preprocessor_era, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06fee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataloaders for the corresponding eras\n",
    "# (note: could make one big dataloader for eras together,\n",
    "#  but this makes correct preprocessing a bit harder as it depends on the era,\n",
    "#  so keep dataloaders separate per era for now)\n",
    "\n",
    "dataloaders = {}\n",
    "for era in eras:\n",
    "    dataloaders[era] = MEDataLoader([files[era]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa87ae16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over eras for training\n",
    "\n",
    "nmfs = {}\n",
    "batch_size = 3000\n",
    "\n",
    "do_plot_components = False\n",
    "\n",
    "for era in eras:\n",
    "    print(f'Now running on era {era}...')\n",
    "    nrows = sum(dataloaders[era].nrows)\n",
    "    nbatches = min(30, max(1, 3*int(nrows/batch_size)))\n",
    "    print(f'Will train on {nbatches} batches of size {batch_size}.')\n",
    "    \n",
    "    # make the NMF model for this era\n",
    "    nmf = NMF2D(n_components=15, forget_factor=1, batch_size=batch_size, verbose=True,\n",
    "                tol=0.0, max_no_improvement=100, max_iter=1000,\n",
    "                alpha_H=0.1)\n",
    "\n",
    "    # training settings\n",
    "    verbose = True\n",
    "    min_entries = 0.5e6\n",
    "    dataloader = dataloaders[era]\n",
    "    preprocessor = preprocessors[era]\n",
    "    \n",
    "    # loop over random batches\n",
    "    for batchidx in range(nbatches):\n",
    "\n",
    "        # load batch\n",
    "        if verbose: print(f'Now processing batch {batchidx+1} / {nbatches}...')\n",
    "        df = dataloader.read_random_batch(batch_size=batch_size, mode='subbatched', num_subbatches=100)\n",
    "        ndf = len(df)\n",
    "\n",
    "        # filtering\n",
    "        if min_entries is not None: df = df[df['entries'] > min_entries]\n",
    "        if verbose: print(f'  Found {len(df)} / {ndf} instances passing filters.')\n",
    "        if len(df)==0: continue\n",
    "\n",
    "        # do preprocessing\n",
    "        if preprocessor is not None:\n",
    "            if verbose: print('  Preprocessing...')\n",
    "            mes_preprocessed = preprocessor.preprocess(df)\n",
    "        else:\n",
    "            mes_preprocessed, _, _ = dftools.get_mes(df,\n",
    "                                       xbinscolumn='x_bin', ybinscolumn='y_bin',\n",
    "                                       runcolumn='run_number', lumicolumn='ls_number')\n",
    "            \n",
    "        # experimental: set zero-occupancy to 1 (average expected value after preprocessing)\n",
    "        mes_preprocessed[mes_preprocessed==0] = 1\n",
    "\n",
    "        # fit NMF\n",
    "        if verbose: print('  Training NMF...')\n",
    "        nmf.fit(mes_preprocessed)\n",
    "        nmfs[era] = nmf\n",
    "        \n",
    "    # plot components\n",
    "    if do_plot_components:\n",
    "        C = nmf.components\n",
    "        for idx in range(len(C)):\n",
    "            fig, ax = plottools.plot_hist_2d(C[idx],\n",
    "                   title=f'Component {idx+1}', titlesize=15,\n",
    "                   xaxtitle=None, xaxtitlesize=None, yaxtitle=None, yaxtitlesize=None,\n",
    "                   ticklabelsize=12, colorticklabelsize=12, extent=None, aspect=None,\n",
    "                   docolorbar=True, caxtitle='Number of clusters\\n(normalized)',\n",
    "                   caxrange=(1e-6, 2),\n",
    "                   caxtitlesize=15, caxtitleoffset=35,\n",
    "                   origin='lower')\n",
    "            title = me.split('-')[-1]\n",
    "            ax.text(0.01, 1.3, title, fontsize=15, transform=ax.transAxes)\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7cb97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the models\n",
    "\n",
    "dosave = False\n",
    "\n",
    "if dosave:\n",
    "    outputdir = f'models/PXLayer_{layer}'\n",
    "    if not os.path.exists(outputdir): os.makedirs(outputdir)\n",
    "\n",
    "    for era in eras:\n",
    "        outputfile = os.path.join(outputdir, f'nmf_model_era{era}.pkl')\n",
    "        joblib.dump(nmfs[era], outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c9a4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over eras for plotting random examples\n",
    "\n",
    "nplot = 1\n",
    "\n",
    "for era in eras:\n",
    "    print(f'Now running on era {era}...')\n",
    "\n",
    "    # calculate random indices\n",
    "    print('Loading data...')\n",
    "    df = iotools.read_parquet(files[era], columns=['run_number', 'ls_number', 'entries'])\n",
    "    ids = np.arange(len(df))\n",
    "    mask = (df['entries'].values > 0.5e6).astype(bool)\n",
    "    print(f'Found {len(ids)} lumisections in this era, of which {np.sum(mask)} pass the selection.')\n",
    "    ids = ids[mask]\n",
    "    random_ids = np.random.choice(ids, size=nplot, replace=False)\n",
    "    selected_run_numbers = df['run_number'].values[random_ids]\n",
    "    selected_ls_numbers = df['ls_number'].values[random_ids]\n",
    "    \n",
    "    # alternative: select specific lumisections\n",
    "    selected_lumis = [(383155, 1700)]\n",
    "    selected_run_numbers = [el[0] for el in selected_lumis]\n",
    "    selected_ls_numbers = [el[1] for el in selected_lumis]\n",
    "    \n",
    "    # load the data\n",
    "    df = iotools.read_lumisections(files[era], selected_run_numbers, selected_ls_numbers)\n",
    "    mes, runs, lumis = dftools.get_mes(df, xbinscolumn='x_bin', ybinscolumn='y_bin', runcolumn='run_number', lumicolumn='ls_number')\n",
    "    \n",
    "    # preprocess and predict\n",
    "    print('Processing...')\n",
    "    mes_preprocessed = preprocessors[era].preprocess(df)\n",
    "    #mes_preprocessed, _, _ = dftools.get_mes(df,\n",
    "    #                           xbinscolumn='x_bin', ybinscolumn='y_bin',\n",
    "    #                           runcolumn='run_number', lumicolumn='ls_number')\n",
    "    mes_pred = nmfs[era].predict(mes_preprocessed)\n",
    "    losses = np.square(mes_preprocessed - mes_pred)\n",
    "\n",
    "    print('Plotting...')\n",
    "    for idx in range(len(df)):\n",
    "        run = runs[idx]\n",
    "        lumi = lumis[idx]\n",
    "        me_orig = mes[idx, :, :]\n",
    "        me_preprocessed = mes_preprocessed[idx, :, :]\n",
    "        me_pred = mes_pred[idx, :, :]\n",
    "        loss = losses[idx, :, :]\n",
    "    \n",
    "        fig, axs = plt.subplots(ncols=4, figsize=(24, 6))\n",
    "        fig, axs[0] = plottools.plot_hist_2d(me_orig, fig=fig, ax=axs[0],\n",
    "                   title='Raw', titlesize=15,\n",
    "                   xaxtitle=None, xaxtitlesize=None, yaxtitle=None, yaxtitlesize=None,\n",
    "                   ticklabelsize=12, colorticklabelsize=12, extent=None, aspect=None,\n",
    "                   docolorbar=True, caxtitle='Number of clusters',\n",
    "                   caxtitlesize=15, caxtitleoffset=15,\n",
    "                   origin='lower')\n",
    "        fig, axs[1] = plottools.plot_hist_2d(me_preprocessed, fig=fig, ax=axs[1],\n",
    "                   title='Input', titlesize=15,\n",
    "                   xaxtitle=None, xaxtitlesize=None, yaxtitle=None, yaxtitlesize=None,\n",
    "                   ticklabelsize=12, colorticklabelsize=12, extent=None, aspect=None,\n",
    "                   docolorbar=True, caxtitle='Number of clusters\\n(normalized)',\n",
    "                   caxrange=(1e-6,2),\n",
    "                   caxtitlesize=15, caxtitleoffset=30,\n",
    "                   origin='lower')\n",
    "        fig, axs[2] = plottools.plot_hist_2d(me_pred, fig=fig, ax=axs[2],\n",
    "                   title='Reconstructed', titlesize=15,\n",
    "                   xaxtitle=None, xaxtitlesize=None, yaxtitle=None, yaxtitlesize=None,\n",
    "                   ticklabelsize=12, colorticklabelsize=12, extent=None, aspect=None,\n",
    "                   docolorbar=True, caxtitle='Number of clusters\\n(normalized)',\n",
    "                   caxrange=(1e-6,2),\n",
    "                   caxtitlesize=15, caxtitleoffset=30,\n",
    "                   origin='lower')\n",
    "        fig, axs[3] = plottools.plot_hist_2d(loss, fig=fig, ax=axs[3],\n",
    "                   title='Loss', titlesize=15,\n",
    "                   xaxtitle=None, xaxtitlesize=None, yaxtitle=None, yaxtitlesize=None,\n",
    "                   ticklabelsize=12, colorticklabelsize=12, extent=None, aspect=None,\n",
    "                   docolorbar=True, caxtitle='Loss',\n",
    "                   caxrange=(0.0, 0.1),\n",
    "                   caxtitlesize=15, caxtitleoffset=30,\n",
    "                   origin='lower')\n",
    "        plt.subplots_adjust(wspace=0.5)\n",
    "        title = f'Run {run}, LS {lumi}, layer {layer}'\n",
    "        axs[0].text(0.01, 1.3, title, fontsize=15, transform=axs[0].transAxes)\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3347055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
