{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3bc931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import joblib\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "thisdir = os.getcwd()\n",
    "topdir = os.path.abspath(os.path.join(thisdir, '../../../'))\n",
    "sys.path.append(topdir)\n",
    "\n",
    "import tools.iotools as iotools\n",
    "import tools.dftools as dftools\n",
    "import tools.patternfiltering as patternfiltering\n",
    "import tools.rebinning as rebinning\n",
    "import plotting.plottools as plottools\n",
    "from tools.dataloadertools import MEDataLoader\n",
    "\n",
    "from studies.clusters_2024.preprocessing.preprocessor import make_default_preprocessor\n",
    "from studies.clusters_2024.preprocessing.preprocessor import PreProcessor\n",
    "from studies.clusters_2024.nmf.modeldefs.nmf2d import NMF2D\n",
    "from studies.clusters_2024.nmf.nmf_training import find_files\n",
    "from studies.clusters_2024.nmf.nmf_testing_pattern import run_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a1c0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to files\n",
    "\n",
    "layers = [1, 2]\n",
    "input_files = {layer: find_files(layer) for layer in layers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d36577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define runs to use in training\n",
    "\n",
    "era = 'F-v1'\n",
    "dftemp = iotools.read_parquet(input_files[layers[0]][era], columns=['run_number', 'entries'])\n",
    "dftemp = dftemp[dftemp['entries'] > 0.5e6]\n",
    "available_runs = np.unique(dftemp['run_number'].values)\n",
    "print('Available runs:')\n",
    "print(available_runs)\n",
    "\n",
    "training_runs = [382649, 382650]\n",
    "print('Chosen training runs:')\n",
    "print(training_runs)\n",
    "\n",
    "# check\n",
    "for training_run in training_runs:\n",
    "    if training_run not in available_runs:\n",
    "        raise Exception(f'Run {training_run} not in available runs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c902b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make preprocessors for the corresponding era\n",
    "\n",
    "preprocessors = {}\n",
    "preprocessor_era = era\n",
    "if '-part' in preprocessor_era: preprocessor_era = era.split('-part')[0]\n",
    "for layer in layers:\n",
    "    preprocessors[layer] = make_default_preprocessor(preprocessor_era, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7014ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "\n",
    "dfs_training = {}\n",
    "for layer in layers:\n",
    "    print(f'Loading training data for layer {layer}...')\n",
    "    dfs_training[layer] = iotools.read_runs(input_files[layer][era], training_runs, verbose=True)\n",
    "ndf = len(dfs_training[layers[0]])\n",
    "print(f'Found {ndf} instances.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa87ae16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do training\n",
    "\n",
    "nmfs = {}\n",
    "batch_size = 300\n",
    "nbatches = 10\n",
    "\n",
    "do_plot_components = True\n",
    "\n",
    "# loop over layers\n",
    "for layer in layers:\n",
    "    print(f'Now running on layer {layer}...')\n",
    "    print(f'Will train on {nbatches} batches of size {batch_size}.')\n",
    "    \n",
    "    # make the NMF model for this layer\n",
    "    nmf = NMF2D(n_components=5, forget_factor=1, batch_size=batch_size, verbose=True,\n",
    "                tol=0.0, max_no_improvement=100, max_iter=1000,\n",
    "                alpha_H=0.1)\n",
    "    \n",
    "    # load the data\n",
    "    df = dfs_training[layer]\n",
    "    \n",
    "    # filtering\n",
    "    df = df[df['entries'] > 0.5e6/layer]\n",
    "    print(f'  Found {len(df)} / {ndf} instances passing filters.')\n",
    "    if len(df)==0: continue\n",
    "        \n",
    "    # preprocessing\n",
    "    mes_preprocessed = preprocessors[layer].preprocess(df)\n",
    "        \n",
    "    # experimental: set zero-occupancy to 1 (average expected value after preprocessing)\n",
    "    mes_preprocessed[mes_preprocessed==0] = 1\n",
    "    \n",
    "    # loop over random batches\n",
    "    for batchidx in range(nbatches):\n",
    "        print(f'Now processing batch {batchidx+1} / {nbatches}...')\n",
    "\n",
    "        # make random indices\n",
    "        random_ids = np.random.choice(np.arange(len(mes_preprocessed)), size=batch_size, replace=False)\n",
    "        batch = mes_preprocessed[random_ids, :, :]\n",
    "\n",
    "        # fit NMF\n",
    "        nmf.fit(batch)\n",
    "        \n",
    "    nmfs[layer] = nmf\n",
    "        \n",
    "    # plot components\n",
    "    if do_plot_components:\n",
    "        C = nmf.components\n",
    "        for idx in range(len(C)):\n",
    "            fig, ax = plottools.plot_hist_2d(C[idx],\n",
    "                   title=f'Component {idx+1}', titlesize=15,\n",
    "                   xaxtitle=None, xaxtitlesize=None, yaxtitle=None, yaxtitlesize=None,\n",
    "                   ticklabelsize=12, colorticklabelsize=12, extent=None, aspect=None,\n",
    "                   docolorbar=True, caxtitle='Number of clusters\\n(normalized)',\n",
    "                   caxrange=(1e-6, 2),\n",
    "                   caxtitlesize=15, caxtitleoffset=35,\n",
    "                   origin='lower')\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7cb97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the models\n",
    "\n",
    "dosave = False\n",
    "\n",
    "if dosave:\n",
    "    outputdir = f'models/PXLayer_{layer}'\n",
    "    if not os.path.exists(outputdir): os.makedirs(outputdir)\n",
    "\n",
    "    for era in eras:\n",
    "        outputfile = os.path.join(outputdir, f'nmf_model_era{era}.pkl')\n",
    "        joblib.dump(nmfs[era], outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76febb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define runs/lumisections for testing\n",
    "\n",
    "# for now, just pick one or multiple runs, later implement selection of specific LS range\n",
    "\n",
    "testing_runs = [382654]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbcf1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings for automasking\n",
    "\n",
    "do_automasking = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b4aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings for loss masking\n",
    "\n",
    "do_loss_masking = True\n",
    "\n",
    "if do_loss_masking:\n",
    "    loss_mask_era = era\n",
    "    if '-part' in era: loss_mask_era = era.split('-part')[0]\n",
    "    loss_masks = {}\n",
    "    loss_mask_preprocessors = {}\n",
    "    for layer in layers:\n",
    "        zerofrac_file = f'../preprocessing/normdata/zerofrac_Run2024{loss_mask_era}_PXLayer_{layer}.npy'\n",
    "        zerofrac = np.load(zerofrac_file)\n",
    "        loss_mask = (zerofrac < 0.9)\n",
    "        loss_masks[layer] = loss_mask\n",
    "        loss_mask_preprocessors[layer] = PreProcessor(f'PXLayer_{layer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f460f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other evaluation settings\n",
    "\n",
    "threshold = 0.1\n",
    "flag_patterns = [np.ones((1,4))]\n",
    "\n",
    "# cleaning\n",
    "do_per_layer_cleaning = True\n",
    "cleaning_patterns = [np.ones((2,8))]\n",
    "cleaning_threshold = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c5148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the testing data\n",
    "\n",
    "dfs_testing = {}\n",
    "for layer in layers:\n",
    "    print(f'Loading testing data for layer {layer}...')\n",
    "    dfs_testing[layer] = iotools.read_runs(input_files[layer][era], testing_runs, verbose=True)\n",
    "ndf = len(dfs_testing[layers[0]])\n",
    "print(f'Found {ndf} instances.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef835b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the testing data\n",
    "\n",
    "flagged_run_numbers, flagged_ls_numbers = run_evaluation(dfs_testing, nmfs,\n",
    "                     preprocessors = preprocessors,\n",
    "                     threshold = threshold,\n",
    "                     flag_patterns = flag_patterns,\n",
    "                     do_per_layer_cleaning = do_per_layer_cleaning,\n",
    "                     cleaning_patterns = cleaning_patterns,\n",
    "                     cleaning_threshold = cleaning_threshold,\n",
    "                     do_automasking = False,\n",
    "                     automask_reader = None,\n",
    "                     automask_map_preprocessors = None,\n",
    "                     do_loss_masking = do_loss_masking,\n",
    "                     loss_masks = loss_masks,\n",
    "                     loss_mask_preprocessors = loss_mask_preprocessors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692f32e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printouts\n",
    "print(f'Found {len(flagged_run_numbers)} flagged lumisections:')\n",
    "for run_number, ls_number in zip(flagged_run_numbers, flagged_ls_numbers):\n",
    "    print(f'  - Run {run_number}, LS {ls_number}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3347055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some random (or not random) examples\n",
    "\n",
    "# general settings\n",
    "do_extended_loss_plots = True\n",
    "do_combined_loss_plot = True\n",
    "\n",
    "# random lumisections\n",
    "nplot = 3\n",
    "#random_ids = np.random.choice(len(available_run_numbers), size=min(nplot, len(available_run_numbers)), replace=False)\n",
    "#selected_run_numbers = available_run_numbers[random_ids]\n",
    "#selected_ls_numbers = available_ls_numbers[random_ids]\n",
    "random_ids = np.random.choice(len(flagged_run_numbers), size=min(nplot, len(flagged_run_numbers)), replace=False)\n",
    "selected_run_numbers = flagged_run_numbers[random_ids]\n",
    "selected_ls_numbers = flagged_ls_numbers[random_ids]\n",
    "\n",
    "# alternative: specific selected lumisections\n",
    "#selected_runlumis = [(385443, 1566), (385443, 1578), (385443, 1579), (385443, 1592)]\n",
    "#selected_run_numbers = [el[0] for el in selected_runlumis]\n",
    "#selected_ls_numbers = [el[1] for el in selected_runlumis]\n",
    "\n",
    "if len(selected_run_numbers) > 0:\n",
    "    \n",
    "    # calculate random indices and load data\n",
    "    print('Loading data...')\n",
    "    dfs = {}\n",
    "    mes = {}\n",
    "    for layer in layers:\n",
    "        dfs[layer] = iotools.read_lumisections(input_files[layer][era], selected_run_numbers, selected_ls_numbers)\n",
    "        mes[layer], runs, lumis = dftools.get_mes(dfs[layer], xbinscolumn='x_bin', ybinscolumn='y_bin', runcolumn='run_number', lumicolumn='ls_number')\n",
    "    \n",
    "    # preprocess and predict\n",
    "    print('Processing...')\n",
    "    mes_preprocessed = {}\n",
    "    mes_pred = {}\n",
    "    losses = {}\n",
    "    losses_binary = {}\n",
    "    for layer in layers:\n",
    "        mes_preprocessed[layer] = preprocessors[layer].preprocess(dfs[layer])\n",
    "        mes_pred[layer] = nmfs[layer].predict(mes_preprocessed[layer])\n",
    "        losses[layer] = np.square(mes_preprocessed[layer] - mes_pred[layer])\n",
    "        losses_binary[layer] = (losses[layer] > threshold).astype(int)\n",
    "    \n",
    "    # automasking\n",
    "    if do_automasking:\n",
    "        print('Applying automasks...')\n",
    "        for layer in layers:\n",
    "            subsystem = f'BPix{layer}'\n",
    "            automask_maps = automask_reader.get_automask_maps_for_ls(selected_run_numbers, selected_ls_numbers, subsystem, invert=True)\n",
    "            automask_maps = automask_map_preprocessors[layer].preprocess_mes(automask_maps, None, None)\n",
    "            losses[layer] = np.multiply(losses[layer], automask_maps)\n",
    "            losses_binary[layer] = np.multiply(losses_binary[layer], automask_maps)\n",
    "            \n",
    "    # manual masking\n",
    "    if do_loss_masking:\n",
    "        print('Applying loss mask...')\n",
    "        for layer in layers:\n",
    "            mask = loss_masks[layer]\n",
    "            mask = np.expand_dims(mask, 0)\n",
    "            mask = loss_mask_preprocessors[layer].preprocess_mes(mask, None, None)\n",
    "            losses[layer] = np.multiply(losses[layer], mask)\n",
    "            losses_binary[layer] = np.multiply(losses_binary[layer], mask)\n",
    "            \n",
    "    # cleaning\n",
    "    if do_per_layer_cleaning:\n",
    "        print('Cleaning loss maps')\n",
    "        losses_binary_cleaned = {}\n",
    "        for layer in layers:\n",
    "            losses_binary_cleaned[layer] = patternfiltering.filter_any_pattern(losses_binary[layer], cleaning_patterns, threshold=cleaning_threshold)\n",
    "    \n",
    "    # make rebinned and overlayed binary loss map\n",
    "    target_shape = losses[layers[0]].shape[1:3]\n",
    "    losses_binary_rebinned = {}\n",
    "    losses_binary_combined = np.zeros(losses[layers[0]].shape)\n",
    "    for layer in layers:\n",
    "        source = losses_binary[layer]\n",
    "        if do_per_layer_cleaning: source = losses_binary_cleaned[layer]\n",
    "        losses_binary_rebinned[layer] = rebinning.rebin_keep_clip(source, target_shape, 1, mode='cv2')\n",
    "        losses_binary_combined += losses_binary_rebinned[layer]\n",
    "    losses_binary_combined = (losses_binary_combined >= 2).astype(int)\n",
    "        \n",
    "    # make the plots\n",
    "    print('Plotting...')\n",
    "    for idx in range(len(selected_run_numbers)):\n",
    "        run = runs[idx]\n",
    "        lumi = lumis[idx]\n",
    "        for layer in layers:\n",
    "            me_orig = mes[layer][idx, :, :]\n",
    "            me_preprocessed = mes_preprocessed[layer][idx, :, :]\n",
    "            me_pred = mes_pred[layer][idx, :, :]\n",
    "            loss = losses[layer][idx, :, :]\n",
    "            loss_binary = losses_binary[layer][idx, :, :]\n",
    "            loss_binary_cleaned = losses_binary_cleaned[layer][idx, :, :]\n",
    "            loss_binary_rebinned = losses_binary_rebinned[layer][idx, :, :]\n",
    "    \n",
    "            # initialize figure\n",
    "            nrows = 1\n",
    "            figheight = 6\n",
    "            if do_extended_loss_plots:\n",
    "                nrows = 2\n",
    "                figheight = 12\n",
    "            fig, axs = plt.subplots(ncols=4, nrows=nrows, figsize=(24, figheight), squeeze=False)\n",
    "            \n",
    "            # plot raw data\n",
    "            fig, axs[0, 0] = plottools.plot_hist_2d(me_orig, fig=fig, ax=axs[0, 0],\n",
    "                   title='Raw', titlesize=15,\n",
    "                   xaxtitle=None, xaxtitlesize=None, yaxtitle=None, yaxtitlesize=None,\n",
    "                   ticklabelsize=12, colorticklabelsize=12, extent=None, aspect=None,\n",
    "                   docolorbar=True, caxtitle='Number of clusters',\n",
    "                   caxtitlesize=15, caxtitleoffset=15,\n",
    "                   origin='lower')\n",
    "        \n",
    "            # overlay automask\n",
    "            if do_automasking:\n",
    "                subsystem = f'BPix{layer}'\n",
    "                automask_map = amreader.get_automask_map_for_ls(run, lumi, subsystem)\n",
    "                ids = np.nonzero(automask_map.astype(int))\n",
    "                for yidx, xidx in zip(ids[0], ids[1]):\n",
    "                    linewidth = 1 if layer>=3 else 2\n",
    "                    patch = mpl.patches.Rectangle((xidx-0.5, yidx-0.5), 1, 1,\n",
    "                                      edgecolor='red', linewidth=linewidth,\n",
    "                                      facecolor='none')\n",
    "                    axs[0, 0].add_patch(patch)\n",
    "        \n",
    "            # plot preprocessed, reconstructed and loss\n",
    "            fig, axs[0, 1] = plottools.plot_hist_2d(me_preprocessed, fig=fig, ax=axs[0, 1],\n",
    "                   title='Input', titlesize=15,\n",
    "                   xaxtitle=None, xaxtitlesize=None, yaxtitle=None, yaxtitlesize=None,\n",
    "                   ticklabelsize=12, colorticklabelsize=12, extent=None, aspect=None,\n",
    "                   docolorbar=True, caxtitle='Number of clusters\\n(normalized)',\n",
    "                   caxrange=(1e-6,2),\n",
    "                   caxtitlesize=15, caxtitleoffset=30,\n",
    "                   origin='lower')\n",
    "            fig, axs[0, 2] = plottools.plot_hist_2d(me_pred, fig=fig, ax=axs[0, 2],\n",
    "                   title='Reconstructed', titlesize=15,\n",
    "                   xaxtitle=None, xaxtitlesize=None, yaxtitle=None, yaxtitlesize=None,\n",
    "                   ticklabelsize=12, colorticklabelsize=12, extent=None, aspect=None,\n",
    "                   docolorbar=True, caxtitle='Number of clusters\\n(normalized)',\n",
    "                   caxrange=(1e-6,2),\n",
    "                   caxtitlesize=15, caxtitleoffset=30,\n",
    "                   origin='lower')\n",
    "            fig, axs[0, 3] = plottools.plot_hist_2d(loss, fig=fig, ax=axs[0, 3],\n",
    "                   title='Loss', titlesize=15,\n",
    "                   xaxtitle=None, xaxtitlesize=None, yaxtitle=None, yaxtitlesize=None,\n",
    "                   ticklabelsize=12, colorticklabelsize=12, extent=None, aspect=None,\n",
    "                   docolorbar=True, caxtitle='Loss',\n",
    "                   caxrange=(0, 0.1),\n",
    "                   caxtitlesize=15, caxtitleoffset=30,\n",
    "                   origin='lower')\n",
    "            \n",
    "            # optional: plot more post-processing steps with the loss map\n",
    "            if do_extended_loss_plots:\n",
    "                fig, axs[1, 0] = plottools.plot_hist_2d(loss_binary, fig=fig, ax=axs[1, 0],\n",
    "                   title=f'Binary loss', titlesize=15,\n",
    "                   xaxtitle=None, xaxtitlesize=None, yaxtitle=None, yaxtitlesize=None,\n",
    "                   ticklabelsize=12, colorticklabelsize=12, extent=None, aspect=None,\n",
    "                   docolorbar=True, caxtitle='Loss',\n",
    "                   caxrange=(0, 1),\n",
    "                   caxtitlesize=15, caxtitleoffset=15,\n",
    "                   origin='lower')\n",
    "                fig, axs[1, 1] = plottools.plot_hist_2d(loss_binary_cleaned, fig=fig, ax=axs[1, 1],\n",
    "                   title=f'Cleaned loss', titlesize=15,\n",
    "                   xaxtitle=None, xaxtitlesize=None, yaxtitle=None, yaxtitlesize=None,\n",
    "                   ticklabelsize=12, colorticklabelsize=12, extent=None, aspect=None,\n",
    "                   docolorbar=True, caxtitle='Loss',\n",
    "                   caxrange=(0, 1),\n",
    "                   caxtitlesize=15, caxtitleoffset=15,\n",
    "                   origin='lower')\n",
    "                fig, axs[1, 2] = plottools.plot_hist_2d(loss_binary_rebinned, fig=fig, ax=axs[1, 2],\n",
    "                   title=f'Rebinned loss', titlesize=15,\n",
    "                   xaxtitle=None, xaxtitlesize=None, yaxtitle=None, yaxtitlesize=None,\n",
    "                   ticklabelsize=12, colorticklabelsize=12, extent=None, aspect=None,\n",
    "                   docolorbar=True, caxtitle='Loss',\n",
    "                   caxrange=(0, 1),\n",
    "                   caxtitlesize=15, caxtitleoffset=15,\n",
    "                   origin='lower')\n",
    "                fig.delaxes(axs[1, 3])\n",
    "                \n",
    "            \n",
    "            # plot aesthetics\n",
    "            plt.subplots_adjust(wspace=0.5)\n",
    "            if str(layer)=='1': plt.subplots_adjust(hspace=-0.75)\n",
    "            if str(layer)=='2': plt.subplots_adjust(hspace=-0.4)\n",
    "            title = f'Run {run}, LS {lumi}, layer {layer}'\n",
    "            axs[0, 0].text(0.01, 1.3, title, fontsize=15, transform=axs[0, 0].transAxes)\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "        # plot the combined loss map\n",
    "        if do_combined_loss_plot:\n",
    "            loss_binary_combined = losses_binary_combined[idx, :, :]\n",
    "            fig, ax = plt.subplots()\n",
    "            fig, ax = plottools.plot_hist_2d(loss_binary_combined, fig=fig, ax=ax,\n",
    "                   title='Combined binary loss', titlesize=15,\n",
    "                   xaxtitle=None, xaxtitlesize=None, yaxtitle=None, yaxtitlesize=None,\n",
    "                   ticklabelsize=12, colorticklabelsize=12, extent=None, aspect=None,\n",
    "                   docolorbar=True, caxtitle='Loss',\n",
    "                   caxrange=(0, 1),\n",
    "                   caxtitlesize=15, caxtitleoffset=15,\n",
    "                   origin='lower')\n",
    "            title = f'Run {run}, LS {lumi}'\n",
    "            ax.text(0.01, 1.3, title, fontsize=15, transform=ax.transAxes)\n",
    "            plt.show()\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8434f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
