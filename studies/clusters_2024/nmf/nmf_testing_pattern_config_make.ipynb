{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3bc931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import copy\n",
    "import importlib\n",
    "import numpy as np\n",
    "\n",
    "thisdir = os.getcwd()\n",
    "topdir = os.path.abspath(os.path.join(thisdir, '../../../'))\n",
    "sys.path.append(topdir)\n",
    "\n",
    "from studies.clusters_2024.preprocessing.preprocessor import get_metype\n",
    "from studies.clusters_2024.nmf.nmf_training import find_files\n",
    "import studies.clusters_2024.nmf.nmf_testing_pattern as evaltools\n",
    "importlib.reload(evaltools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96398157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# era and layer settings\n",
    "\n",
    "eras = [\n",
    "    'B-v1',\n",
    "    'C-v1',\n",
    "    'D-v1',\n",
    "    'E-v1',\n",
    "    'E-v2',\n",
    "    'F-v1',\n",
    "    'F-v1-part1',\n",
    "    'F-v1-part2',\n",
    "    'F-v1-part3',\n",
    "    'F-v1-part4',\n",
    "    'G-v1',\n",
    "    'G-v1-part1',\n",
    "    'G-v1-part2',\n",
    "    'G-v1-part3',\n",
    "    'G-v1-part4',\n",
    "    'H-v1',\n",
    "    'I-v1',\n",
    "    'I-v2'\n",
    "]\n",
    "layers = ['BPix1', 'BPix2', 'BPix3', 'BPix4']\n",
    "\n",
    "# initialize config\n",
    "config = {}\n",
    "config['eras'] = eras\n",
    "config['layers'] = layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a1c0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to input files\n",
    "\n",
    "# settings\n",
    "datadir = '/eos/user/l/llambrec/dialstools-output'\n",
    "year = '2024'\n",
    "dataset = 'ZeroBias'\n",
    "reco = 'PromptReco'\n",
    "mebase = 'PixelPhase1-Phase1_MechanicalView-PXBarrel-clusters_per_SignedModuleCoord_per_SignedLadderCoord_PXLayer_{}'\n",
    "\n",
    "# find files corresponding to settings\n",
    "input_files = {}\n",
    "for era in eras:\n",
    "    mainera, version = era.split('-', 1)\n",
    "    input_files[era] = {}\n",
    "    for layer in layers:\n",
    "        me = mebase.format(layer[-1])\n",
    "        f = f'{dataset}-Run{year}{mainera}-{reco}-{version}-DQMIO-{me}.parquet'\n",
    "        f = os.path.join(datadir, f)\n",
    "        input_files[era][layer] = [f]\n",
    "\n",
    "# existence check\n",
    "missing = []\n",
    "present = []\n",
    "for era, values in input_files.items():\n",
    "    for layer, files in values.items():\n",
    "        for f in files:\n",
    "            if not os.path.exists(f): missing.append(f)\n",
    "            else: present.append(f)\n",
    "if len(missing) > 0:\n",
    "    raise Exception(f'The following files do not exist: {missing}')\n",
    "else:\n",
    "    print(f'Found {len(present)} files.')\n",
    "    \n",
    "# add to config\n",
    "config['input_files'] = input_files\n",
    "print(json.dumps(input_files, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13525e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to nmf model files\n",
    "\n",
    "modeldir = 'output_20250604/models'\n",
    "\n",
    "# set up how to match eras\n",
    "# options:\n",
    "# - current era for each input file (e.g. for offline application)\n",
    "# - previous era for each input file (e.g. for online application)\n",
    "# - one and the same era for each input file\n",
    "\n",
    "# use current era\n",
    "#model_eradict = {era: era for era in eras}\n",
    "\n",
    "# use previous era\n",
    "#model_eradict = {}\n",
    "#for i in range(len(eras)): model_eradict[eras[i]] = eras[i-1]\n",
    "#model_eradict[eras[0]] = eras[1]\n",
    "\n",
    "# use a fixed era\n",
    "model_eradict = {era: 'C-v1' for era in eras}\n",
    "\n",
    "# set path\n",
    "nmf_files = {}\n",
    "for era in eras:\n",
    "    nmf_files[era] = {}\n",
    "    model_era = model_eradict[era]\n",
    "    for layer in layers: nmf_files[era][layer] = os.path.join(modeldir, f'nmf_model_{layer.upper()}_{model_era}.pkl')\n",
    "    \n",
    "# existence check\n",
    "missing = []\n",
    "for era in eras:\n",
    "    for layer, f in nmf_files[era].items():\n",
    "        if not os.path.exists(f): missing.append(f)\n",
    "if len(missing) > 0:\n",
    "    raise Exception(f'The following files do not exist: {missing}')\n",
    "    \n",
    "# add to config\n",
    "config['nmf_files'] = nmf_files\n",
    "print(json.dumps(nmf_files, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e59cb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings for preprocessing\n",
    "\n",
    "config['preprocessing_global_normalization'] = 'avg'\n",
    "config['preprocessing_local_normalization'] = 'avg_era_C-v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb88750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings for filtering\n",
    "\n",
    "# min entries filter\n",
    "min_entries_filter = {\n",
    "    'BPix1': 0.5e6,\n",
    "    'BPix2': 0.5e6/2,\n",
    "    'BPix3': 0.5e6/3,\n",
    "    'BPix4': 0.5e6/4\n",
    "}\n",
    "\n",
    "# OMS attribute filters\n",
    "oms_filter_files = {}\n",
    "oms_filters = []\n",
    "for era in eras:\n",
    "    oms_era = era\n",
    "    if '-part' in era: oms_era = era.split('-part')[0]\n",
    "    oms_filter_files[era] = f'/eos/user/l/llambrec/pixelae/studies/clusters_2024/omsdata/omsdata_Run2024{oms_era}.json'\n",
    "for oms_filter_file in oms_filter_files.values():\n",
    "    if not os.path.exists(oms_filter_file):\n",
    "        raise Exception(f'File {oms_filter_file} does not exist.')\n",
    "oms_filters = [\n",
    "    [\"beams_stable\"],\n",
    "    [\"cms_active\"],\n",
    "    [\"bpix_ready\"],\n",
    "    [\"fpix_ready\"],\n",
    "    [\"tibtid_ready\"],\n",
    "    [\"tob_ready\"],\n",
    "    [\"tecp_ready\"],\n",
    "    [\"tecm_ready\"],\n",
    "    [\"pileup\", '>', 25]\n",
    "]\n",
    "\n",
    "# HLT rate filter\n",
    "hltrate_filter_files = {}\n",
    "hltrate_filters = []\n",
    "for era in eras:\n",
    "    hltrate_era = era\n",
    "    if '-part' in era: hltrate_era = era.split('-part')[0]\n",
    "    hltrate_filter_files[era] = f'/eos/user/l/llambrec/pixelae/studies/clusters_2024/omsdata/hltrate_Run2024{hltrate_era}.json'\n",
    "for hltrate_filter_file in hltrate_filter_files.values():\n",
    "    if not os.path.exists(hltrate_filter_file):\n",
    "        raise Exception(f'File {hltrate_filter_file} does not exist.')\n",
    "hltrate_filters = [\n",
    "    [\"HLT_ZeroBias_v*\", '>', 5]\n",
    "]\n",
    "\n",
    "# add to config\n",
    "config['min_entries_filter'] = min_entries_filter\n",
    "config['oms_filter_files'] = oms_filter_files\n",
    "config['oms_filters'] = oms_filters\n",
    "config['hltrate_filter_files'] = hltrate_filter_files\n",
    "config['hltrate_filters'] = hltrate_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0f3830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to automask data\n",
    "\n",
    "do_automasking = False\n",
    "\n",
    "automask_data_file = None\n",
    "if do_automasking:\n",
    "    automask_data_dir = '/eos/user/l/llambrec/pixelae/automasking/data/automask_data'\n",
    "    automask_data_file = os.path.join(automask_data_dir, f'automask_2024.json')\n",
    "    if not os.path.exists(automask_data_file):\n",
    "        raise Exception(f'The automask data file {automask_data_file} does not exist.')\n",
    "    config['automask_data_file'] = automask_data_file\n",
    "    \n",
    "# add to config\n",
    "config['do_automasking'] = do_automasking\n",
    "config['automask_data_file'] = automask_data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935e659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to loss mask data\n",
    "\n",
    "do_loss_masking = True\n",
    "loss_masking_zero_frac_threshold = 0.9\n",
    "\n",
    "loss_masking_zero_frac_files = None\n",
    "if do_loss_masking:\n",
    "    loss_masking_zero_frac_files = {}\n",
    "    for era in eras:\n",
    "        loss_mask_era = era\n",
    "        if '-part' in era: loss_mask_era = era.split('-part')[0]\n",
    "        loss_masking_zero_frac_files[era] = {}\n",
    "        for layer in layers:\n",
    "            zerofrac_file = f'/eos/user/l/llambrec/pixelae/studies/clusters_2024/preprocessing/normdata/zerofrac_Run2024{loss_mask_era}_{get_metype(layer)}.npy'\n",
    "            if not os.path.exists(zerofrac_file):\n",
    "                raise Exception(f'The file {zerofrac_file} does not exist.')\n",
    "            loss_masking_zero_frac_files[era][layer] = zerofrac_file\n",
    "\n",
    "# add to config\n",
    "config['do_loss_masking'] = do_loss_masking\n",
    "config['loss_masking_zero_frac_threshold'] = loss_masking_zero_frac_threshold\n",
    "config['loss_masking_zero_frac_files'] = loss_masking_zero_frac_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa87ae16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set evaluation parameters\n",
    "\n",
    "# general\n",
    "batch_size = 3000\n",
    "loss_threshold = 0.04\n",
    "\n",
    "# flagging\n",
    "flagging_patterns = [np.ones((1,8)), np.ones((2,4))]\n",
    "flagging_threshold = 1e-3\n",
    "\n",
    "# cleaning\n",
    "do_per_layer_cleaning = True\n",
    "cleaning_patterns = {\n",
    "    'BPix1': [np.ones((2,16))], # two neighbouring modules\n",
    "    'BPix2': [np.ones((2,16))], # two neighbouring modules\n",
    "    'BPix3': [np.ones((2,16))], # two neighbouring modules\n",
    "    'BPix4': [np.ones((2,16))] # two neighbouring modules\n",
    "}\n",
    "cleaning_threshold = 1.5\n",
    "\n",
    "# add to config\n",
    "config['batch_size'] = batch_size\n",
    "config['loss_threshold'] = loss_threshold\n",
    "config['flagging_patterns'] = [el.tolist() for el in flagging_patterns]\n",
    "config['flagging_threshold'] = flagging_threshold\n",
    "config['do_per_layer_cleaning'] = do_per_layer_cleaning\n",
    "config['cleaning_patterns'] = {key: [el.tolist() for el in val] for key, val in cleaning_patterns.items()}\n",
    "config['cleaning_threshold'] = cleaning_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b13096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directory for this config\n",
    "\n",
    "outputdir = 'output_test_eraCmodel_lowerlossthreshold_higherpileupthreshold'\n",
    "\n",
    "if os.path.exists(outputdir):\n",
    "    msg = f'Output directory {outputdir} already exists.'\n",
    "    raise Exception(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d381f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set output file\n",
    "\n",
    "outputfile = os.path.join(outputdir, 'flagged_lumisections.json')\n",
    "outputfile = os.path.join('/eos/user/l/llambrec/pixelae/studies/clusters_2024/nmf', outputfile)\n",
    "# note: cannot use getwcd() to define the directory above,\n",
    "#       as it seems to give some kind of virtual directory that is ok in the notebook\n",
    "#       but gives errors when used in the lxplus terminal or condor job.\n",
    "\n",
    "config['outputfile'] = outputfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc34976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the configuration\n",
    "\n",
    "split_per_era = True\n",
    "basename = 'temp_config'\n",
    "\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)\n",
    "\n",
    "if split_per_era:\n",
    "    for era in eras:\n",
    "        this_config = copy.deepcopy(config)\n",
    "        this_config['eras'] = [era]\n",
    "        this_config['input_files'] = {era: input_files[era]}\n",
    "        this_config['nmf_files'] = {era: nmf_files[era]}\n",
    "        this_config['oms_filter_files'] = {era: oms_filter_files[era]}\n",
    "        this_config['hltrate_filter_files'] = {era: hltrate_filter_files[era]}\n",
    "        this_config['outputfile'] = outputfile.replace('.json', f'_{era}.json')\n",
    "        if this_config['loss_masking_zero_frac_files'] is not None:\n",
    "            this_config['loss_masking_zero_frac_files'] = {era: loss_masking_zero_frac_files[era]}\n",
    "        configfile = os.path.join(outputdir, f'{basename}_{era}.json')\n",
    "        with open(configfile, 'w') as f:\n",
    "            json.dump(this_config, f)\n",
    "\n",
    "else:\n",
    "    configfile = os.path.join(outputdir, f'{basename}.json')\n",
    "    with open(configfile, 'w') as f:\n",
    "        json.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af48f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: run the configuration\n",
    "\n",
    "#flagged_run_numbers, flagged_ls_numbers = evaltools.evaluate(config)\n",
    "\n",
    "# print flagged lumisections\n",
    "flagged_run_numbers_unique = np.unique(flagged_run_numbers)\n",
    "print(f'  Found {len(flagged_run_numbers)} flagged lumisections in {len(flagged_run_numbers_unique)} runs.')\n",
    "for flagged_run_number, flagged_ls_number in zip(flagged_run_numbers, flagged_ls_numbers):\n",
    "    print(f'- Run {flagged_run_number}, LS {flagged_ls_number}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c3d7e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
