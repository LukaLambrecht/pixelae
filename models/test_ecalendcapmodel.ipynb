{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac3de5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import ecalendcapmodel\n",
    "importlib.reload(ecalendcapmodel)\n",
    "from ecalendcapmodel import ResNetAE, ResNetAEPixel, training_loop\n",
    "\n",
    "# framework modules\n",
    "sys.path.append('../')\n",
    "import plotting.plottools\n",
    "importlib.reload(plotting.plottools)\n",
    "from plotting.plottools import plot_histogram\n",
    "import training.prepare_training_set\n",
    "importlib.reload(training.prepare_training_set)\n",
    "from training.prepare_training_set import prepare_training_data_from_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ff2cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# syntax check on (20x20) images as originally used by ECAL\n",
    "\n",
    "ae = ResNetAE(1, 3, [16, 32], debug=True)\n",
    "x = torch.tensor(np.ones((1,1,20,20)).astype(np.float32))\n",
    "_ = ae(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab19d516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# syntax check on (32x32) images as used here\n",
    "\n",
    "ae = ResNetAEPixel(1, 3, [16, 32], debug=True)\n",
    "x = torch.tensor(np.ones((1,1,32,32)).astype(np.float32))\n",
    "_ = ae(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1826faae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some example data\n",
    "\n",
    "file = '../data/data/ZeroBias-Run2023C-PromptReco-v1-DQMIO-PixelPhase1-Tracks-PXForward-clusterposition_xy_ontrack_PXDisk_+1_preprocessed.parquet'\n",
    "\n",
    "kwargs = ({\n",
    "    'verbose': True,\n",
    "    'entries_threshold': 10000,\n",
    "    'skip_first_lumisections': 5,\n",
    "    'veto_patterns': [np.zeros((2,2)), np.zeros((3,1)), np.zeros((1,3))]\n",
    "})\n",
    "(train_data, training_runs, training_lumis) = prepare_training_data_from_files([file], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765d0cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 32x32 to 20x20\n",
    "\n",
    "#train_data = train_data[:,:20,:20,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34851759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit number of training instances\n",
    "\n",
    "train_data = train_data[:1000, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754c0397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to pytorch tensor\n",
    "\n",
    "train_data_tensor = np.expand_dims(train_data, axis=1)[:,:,:,:,0]\n",
    "train_data_tensor = train_data_tensor.astype(np.float32)\n",
    "train_data_tensor = torch.tensor(train_data_tensor)\n",
    "print(train_data_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475db525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "\n",
    "ae = ResNetAEPixel(1, 1, [16, 32])\n",
    "optimizer = optim.Adam(ae.parameters(), lr=5e-4)\n",
    "\n",
    "epochs = 1\n",
    "batch_size = 50\n",
    "\n",
    "training_loop(ae, train_data_tensor, optimizer, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6536e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot examples\n",
    "\n",
    "nplots = 5\n",
    "plotids = np.random.choice(len(train_data), size=nplots)\n",
    "\n",
    "for i in plotids:\n",
    "    orig = train_data[i,:,:,0]\n",
    "    reco = np.expand_dims(np.expand_dims(orig, axis=0), axis=0)\n",
    "    reco = ae(torch.tensor(reco.astype(np.float32)))\n",
    "    reco = reco[0,0,:,:]\n",
    "    reco = reco.detach().numpy()\n",
    "    fig,axs = plt.subplots(figsize=(12,6), ncols=2)\n",
    "    plot_histogram(orig, fig=fig, ax=axs[0])\n",
    "    plot_histogram(reco, fig=fig, ax=axs[1])\n",
    "    axs[0].text(0.02, 1.02, 'Run: {}, lumi: {}'.format(training_runs[i], training_lumis[i]), transform=axs[0].transAxes, fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d6f853",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
