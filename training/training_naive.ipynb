{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c4880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "# external modules\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "# framework modules\n",
    "sys.path.append('../')\n",
    "import plotting.plottools\n",
    "importlib.reload(plotting.plottools)\n",
    "from plotting.plottools import plot_histogram\n",
    "import models.modeldefs\n",
    "importlib.reload(models.modeldefs)\n",
    "from models.modeldefs import model_dummy\n",
    "from models.modeldefs import model_ecal_endcap\n",
    "# local modules\n",
    "import prepare_training_set\n",
    "importlib.reload(prepare_training_set)\n",
    "from prepare_training_set import prepare_training_data_from_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85638d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training set\n",
    "\n",
    "file = '../data/data/ZeroBias-Run2023C-PromptReco-v1-DQMIO-PixelPhase1-Tracks-PXForward-clusterposition_xy_ontrack_PXDisk_+1_preprocessed.parquet'\n",
    "\n",
    "kwargs = ({\n",
    "    'verbose': True,\n",
    "    'entries_threshold': 10000,\n",
    "    'skip_first_lumisections': 5,\n",
    "    'veto_patterns': [np.zeros((2,2)), np.zeros((3,1)), np.zeros((1,3))]\n",
    "})\n",
    "(train_data, training_runs, training_lumis) = prepare_training_data_from_files([file], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbcd5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a mask where values are often zero\n",
    "\n",
    "shape_mask = (np.sum(training_data[:,:,:,0]==0, axis=0)>len(training_data)/2.)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "plot_histogram(shape_mask, fig=fig, ax=ax, caxrange=(-0.01,1))\n",
    "ax.text(0.02, 1.02, 'Shape mask', transform=ax.transAxes, fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb62480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make model and training settings\n",
    "input_shape = training_data.shape[1:]\n",
    "model = model_dummy(input_shape)\n",
    "loss = 'mse'\n",
    "optimizer = 'adam'\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "validation_split = 0.1\n",
    "\n",
    "# compile model\n",
    "model.compile(\n",
    "  loss=loss,\n",
    "  optimizer=optimizer\n",
    ")\n",
    "\n",
    "# do training\n",
    "history = model.fit(\n",
    "    training_data, training_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=True,\n",
    "    shuffle=True,\n",
    "    validation_split=validation_split\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8843e938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "\n",
    "training_predictions = model.predict(training_data)\n",
    "training_predictions[training_predictions<0] = 0.\n",
    "training_predictions[:,shape_mask] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3899fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate squared difference\n",
    "\n",
    "training_errors = np.square(training_data - training_predictions)\n",
    "avg_response = np.square(np.mean(training_data, axis=0)) # average occupancy\n",
    "#avg_response = np.mean(training_errors, axis=0) # average error\n",
    "avg_response[avg_response==0] = 1\n",
    "training_errors_corrected = training_errors/avg_response\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "caxrange = None\n",
    "#caxrange = (-0.001, 0.01)\n",
    "plot_histogram(avg_response[:,:,0], fig=fig, ax=ax, caxrange=caxrange)\n",
    "ax.text(0.02, 1.02, 'Average response', transform=ax.transAxes, fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6338d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots of instances in training set\n",
    "\n",
    "nplots = 5\n",
    "plotids = np.random.choice(len(training_data), size=nplots)\n",
    "\n",
    "for i in plotids:\n",
    "    fig,axs = plt.subplots(figsize=(24,6), ncols=4)\n",
    "    plot_histogram(training_data[i,:,:,0], fig=fig, ax=axs[0])\n",
    "    plot_histogram(training_predictions[i,:,:,0], fig=fig, ax=axs[1])\n",
    "    plot_histogram(training_errors[i,:,:,0], fig=fig, ax=axs[2], caxrange=(-0.001, 0.01))\n",
    "    plot_histogram(training_errors_corrected[i,:,:,0], fig=fig, ax=axs[3], caxrange=(-0.01,0.5))\n",
    "    axs[0].text(0.02, 1.02, 'Run: {}, lumi: {}'.format(training_runs[i], training_lumis[i]), transform=axs[0].transAxes, fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45380b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an evaluation set that is the complement of the training set\n",
    "\n",
    "kwargs = ({\n",
    "    'verbose': True,\n",
    "    'entries_threshold': 10000,\n",
    "    'skip_first_lumisections': 5,\n",
    "    'required_patterns': [np.zeros((2,2)), np.zeros((3,1)), np.zeros((1,3))]\n",
    "})\n",
    "(eval_data, eval_runs, eval_lumis) = prepare_training_data_from_files([file], **kwargs)\n",
    "\n",
    "eval_predictions = model.predict(eval_data)\n",
    "eval_predictions[eval_predictions<0] = 0.\n",
    "eval_predictions[:,shape_mask] = 0.\n",
    "\n",
    "eval_errors = np.square(eval_data - eval_predictions)\n",
    "eval_errors_corrected = eval_errors/avg_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba5a64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nplots = 5\n",
    "plotids = np.random.choice(len(eval_data), size=nplots)\n",
    "\n",
    "for i in plotids:\n",
    "    fig,axs = plt.subplots(figsize=(24,6), ncols=4)\n",
    "    plot_histogram(eval_data[i,:,:,0], fig=fig, ax=axs[0])\n",
    "    plot_histogram(eval_predictions[i,:,:,0], fig=fig, ax=axs[1])\n",
    "    plot_histogram(eval_errors[i,:,:,0], fig=fig, ax=axs[2], caxrange=(-0.001, 0.01))\n",
    "    plot_histogram(eval_errors_corrected[i,:,:,0], fig=fig, ax=axs[3], caxrange=(-0.01, 0.5))\n",
    "    axs[0].text(0.02, 1.02, 'Run: {}, lumi: {}'.format(eval_runs[i], eval_lumis[i]), transform=axs[0].transAxes, fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf5c70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the model\n",
    "\n",
    "dosave = False\n",
    "if dosave:\n",
    "    modelname = 'test_model_20231109_pxdisk+1_era2023Cv1.keras'\n",
    "    model.save(modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef8ad27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
